{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import (\n",
    "    IA3Config,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\"\n",
    "\n",
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "base_model = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer= AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_context</th>\n",
       "      <th>actions_dictionary</th>\n",
       "      <th>query</th>\n",
       "      <th>explanation</th>\n",
       "      <th>bt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a beach chair and umbrella on the beach (28.3m...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>Can you please bring me the bowl of soup and t...</td>\n",
       "      <td>Good, I will first locate the bowl of soup in ...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a table with chairs (21.3m)\\ntwo men standing ...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you identify the man in the black jacket ...</td>\n",
       "      <td>In this scenario, I will first attempt to loca...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a black cow grazing in a field (54.5m)\\na man ...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you locate the person standing in front o...</td>\n",
       "      <td>In this scenario, I will attempt to locate the...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a blur of a person walking on a street (13.5m)...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you display a message on the laptop to re...</td>\n",
       "      <td>I will start by attempting to display a messag...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a group of men playing frc (64.7m)\\na polar be...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you take the bowl filled with fruit and i...</td>\n",
       "      <td>I will first check if there is a bowl filled w...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      object_context  \\\n",
       "0  a beach chair and umbrella on the beach (28.3m...   \n",
       "1  a table with chairs (21.3m)\\ntwo men standing ...   \n",
       "2  a black cow grazing in a field (54.5m)\\na man ...   \n",
       "3  a blur of a person walking on a street (13.5m)...   \n",
       "4  a group of men playing frc (64.7m)\\na polar be...   \n",
       "\n",
       "                                  actions_dictionary  \\\n",
       "0  NavigateTo: Moves the robot to a specified tar...   \n",
       "1  NavigateTo: Moves the robot to a specified tar...   \n",
       "2  NavigateTo: Moves the robot to a specified tar...   \n",
       "3  NavigateTo: Moves the robot to a specified tar...   \n",
       "4  NavigateTo: Moves the robot to a specified tar...   \n",
       "\n",
       "                                               query  \\\n",
       "0  Can you please bring me the bowl of soup and t...   \n",
       "1  \"Can you identify the man in the black jacket ...   \n",
       "2  \"Can you locate the person standing in front o...   \n",
       "3  \"Can you display a message on the laptop to re...   \n",
       "4  \"Can you take the bowl filled with fruit and i...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0  Good, I will first locate the bowl of soup in ...   \n",
       "1  In this scenario, I will first attempt to loca...   \n",
       "2  In this scenario, I will attempt to locate the...   \n",
       "3  I will start by attempting to display a messag...   \n",
       "4  I will first check if there is a bowl filled w...   \n",
       "\n",
       "                                                  bt  \n",
       "0  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "1  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "2  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "3  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "4  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"../data/queries_dataset.json\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree in the behaviortree cpp format.\n",
      "\n",
      "Object Context : \n",
      "a beach chair and umbrella on the beach (28.3m)\n",
      "a woman walking down the street with an umbrella (96.9m)\n",
      "a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Actions Dictionary:\n",
      "NavigateTo: Moves the robot to a specified target (e.g., location or object). (Arguments: target)\n",
      "Pick: Picks up a specified object. (Arguments: object)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "RequestAssistance: Requests help for a specific task. (Arguments: task)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "RunDiagnostics: Runs system diagnostics to check for issues. (Arguments: )\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>Can you please bring me the bowl of soup and t...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you identify the man in the black jacket ...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you locate the person standing in front o...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you display a message on the laptop to re...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you take the bowl filled with fruit and i...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  You are a helpful robot assistant named Goat t...   \n",
       "1  You are a helpful robot assistant named Goat t...   \n",
       "2  You are a helpful robot assistant named Goat t...   \n",
       "3  You are a helpful robot assistant named Goat t...   \n",
       "4  You are a helpful robot assistant named Goat t...   \n",
       "\n",
       "                                               input  \\\n",
       "0  Can you please bring me the bowl of soup and t...   \n",
       "1  \"Can you identify the man in the black jacket ...   \n",
       "2  \"Can you locate the person standing in front o...   \n",
       "3  \"Can you display a message on the laptop to re...   \n",
       "4  \"Can you take the bowl filled with fruit and i...   \n",
       "\n",
       "                                              output  \n",
       "0  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "1  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "2  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "3  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "4  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_context = data['object_context']\n",
    "actions_dictionary = data['actions_dictionary']\n",
    "query = data['query']\n",
    "explanation = data['explanation']\n",
    "bt = data['bt']\n",
    "\n",
    "\n",
    "# Create df with the following columns: instruction, input, output\n",
    "def formatting_input(examples):\n",
    "    instruction = \"\"\"You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree in the behaviortree cpp format.\n",
    "\n",
    "Object Context : \n",
    "{object_context}\n",
    "\n",
    "Actions Dictionary:\n",
    "{actions_dictionary}\n",
    "\"\"\"\n",
    "\n",
    "    instruction = instruction.format(object_context=examples['object_context'], actions_dictionary=examples['actions_dictionary'])\n",
    "    return instruction\n",
    "\n",
    "for i in range(len(data)):\n",
    "    instruction = formatting_input(data.iloc[i])\n",
    "    print(instruction)\n",
    "    break\n",
    "\n",
    "formatted_data = pd.DataFrame({\n",
    "    'instruction': instruction,\n",
    "    'input': query,\n",
    "    'output': bt,\n",
    "})\n",
    "\n",
    "formatted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3feae560fa694770b0d7234e43402060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree in the behaviortree cpp format.\n",
      "\n",
      "Object Context : \n",
      "a beach chair and umbrella on the beach (28.3m)\n",
      "a woman walking down the street with an umbrella (96.9m)\n",
      "a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Actions Dictionary:\n",
      "NavigateTo: Moves the robot to a specified target (e.g., location or object). (Arguments: target)\n",
      "Pick: Picks up a specified object. (Arguments: object)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "RequestAssistance: Requests help for a specific task. (Arguments: task)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "RunDiagnostics: Runs system diagnostics to check for issues. (Arguments: )\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Can you please bring me the bowl of soup and then release it on the table?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "<root main_tree_to_execute=\"MainTree\">\n",
      "  <BehaviorTree ID=\"MainTree\">\n",
      "    <Fallback>\n",
      "      <Sequence>\n",
      "        <Action ID=\"LocateObject\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"NavigateTo\" target=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Pick\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Place\" object=\"bowl_of_soup\" location=\"table\"/>\n",
      "      </Sequence>\n",
      "      <Action ID=\"RequestAssistance\" task=\"find_bowl_of_soup\"/>\n",
      "    </Fallback>\n",
      "  </BehaviorTree>\n",
      "</root>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = \"<|eot_id|>\"\n",
    "\n",
    "def formatting_prompt(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction,input_, output in zip(instructions, inputs, outputs):\n",
    "        text = data_prompt.format(instruction,input_, output)\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "\n",
    "# Create the dataset and apply the mapping\n",
    "training_data = Dataset.from_pandas(formatted_data)\n",
    "training_data = training_data.map(formatting_prompt, batched=True)\n",
    "\n",
    "# Display a sample for verification\n",
    "print(training_data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/simon/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/simon/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436398fa4ee646ccac8b166d5702eb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51c5ca300a946f38090614f25347a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "\n",
    "\n",
    "# LoRA config\n",
    "#peft_config = PrefixTuningConfig(\n",
    "#    num_virtual_tokens=30,  # Number of virtual tokens\n",
    "#    task_type=\"CAUSAL_LM\",  # Task type\n",
    "#)\n",
    "\n",
    "peft_config = IA3Config(task_type=\"CAUSAL_LM\", target_modules=[\"k_proj\", \"v_proj\", \"down_proj\"], feedforward_modules=[\"down_proj\"])\n",
    "\n",
    "\n",
    "\n",
    "new_model = \"llama-3.2-1b-bt-generator-ia3\"\n",
    "\n",
    "#Hyperparamter\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "# Create train/test split\n",
    "full_dataset = training_data.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=full_dataset[\"train\"],\n",
    "    eval_dataset=full_dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3dff1bf83a40ee953b65a3fe5f5f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree in the behaviortree cpp format.\n",
      "\n",
      "Object Context : \n",
      "a beach chair and umbrella on the beach (28.3m)\n",
      "a woman walking down the street with an umbrella (96.9m)\n",
      "a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Actions Dictionary:\n",
      "NavigateTo: Moves the robot to a specified target (e.g., location or object). (Arguments: target)\n",
      "Pick: Picks up a specified object. (Arguments: object)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "RequestAssistance: Requests help for a specific task. (Arguments: task)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "RunDiagnostics: Runs system diagnostics to check for issues. (Arguments: )\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Can you please bring me the bowl of soup and then release it on the table?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "<root main_tree_to_execute=\"MainTree\">\n",
      "  <BehaviorTree ID=\"MainTree\">\n",
      "    <Fallback>\n",
      "      <Sequence>\n",
      "        <Action ID=\"LocateObject\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"NavigateTo\" target=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Pick\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Place\" object=\"bowl_of_soup\" location=\"table\"/>\n",
      "      </Sequence>\n",
      "      <Action ID=\"RequestAssistance\" task=\"find_bowl_of_soup\"/>\n",
      "    </Fallback>\n",
      "  </BehaviorTree>\n",
      "</root>\n"
     ]
    }
   ],
   "source": [
    "data_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = \"<|eot_id|>\"\n",
    "\n",
    "def formatting_prompt(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction,input_, output in zip(instructions, inputs, outputs):\n",
    "        text = data_prompt.format(instruction,input_, output)\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "\n",
    "# Create the dataset and apply the mapping\n",
    "training_data = Dataset.from_pandas(formatted_data)\n",
    "training_data = training_data.map(formatting_prompt, batched=True)\n",
    "\n",
    "# Display a sample for verification\n",
    "print(training_data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer of the question is: \n",
      "I will execute the action \"Pick\" to pick up the bowl of soup from the beach chair.\n",
      "\n",
      "Here is the behavior tree in Cpp format:\n",
      "```cpp\n",
      "NavigateTo(table)\n",
      "  - Pick(bowl of soup)\n",
      "    - MoveForward(5.0m)\n",
      "    - Place(bowl of soup, table)\n",
      "```\n",
      "The bowl of soup is now at the table.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "instructions = training_data[\"instruction\"][0]\n",
    "inputs = training_data[\"input\"][0]\n",
    "outputs = training_data[\"output\"][0]\n",
    "text = data_prompt.format(instructions, inputs, \"\")\n",
    "\n",
    "inputs = tokenizer([\n",
    "    text\n",
    "], return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 2020, use_cache = True)\n",
    "\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer=answer[0].split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimonroy99\u001b[0m (\u001b[33msimonroy99-cole-de-technologie-sup-rieure\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/simon/workspace/ETS/SYS819/proteus/training/wandb/run-20241127_190654-nlqj8c7b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/nlqj8c7b' target=\"_blank\">llama-3.2-1b-bt-generator-ia3</a></strong> to <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface' target=\"_blank\">https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/nlqj8c7b' target=\"_blank\">https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/nlqj8c7b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c20a0f2fcff4f3596c01598c8fb3a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.3277, 'grad_norm': 0.37115049362182617, 'learning_rate': 2e-05, 'epoch': 0.02}\n",
      "{'loss': 2.303, 'grad_norm': 0.3913576900959015, 'learning_rate': 4e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4745, 'grad_norm': 0.4053996503353119, 'learning_rate': 6e-05, 'epoch': 0.07}\n",
      "{'loss': 2.4688, 'grad_norm': 0.4172709882259369, 'learning_rate': 8e-05, 'epoch': 0.09}\n",
      "{'loss': 2.539, 'grad_norm': 0.42384669184684753, 'learning_rate': 0.0001, 'epoch': 0.11}\n",
      "{'loss': 2.5409, 'grad_norm': 0.42062467336654663, 'learning_rate': 0.00012, 'epoch': 0.13}\n",
      "{'loss': 2.5101, 'grad_norm': 0.4310063123703003, 'learning_rate': 0.00014, 'epoch': 0.16}\n",
      "{'loss': 2.6112, 'grad_norm': 0.42962774634361267, 'learning_rate': 0.00016, 'epoch': 0.18}\n",
      "{'loss': 2.9048, 'grad_norm': 0.4854852557182312, 'learning_rate': 0.00018, 'epoch': 0.2}\n",
      "{'loss': 2.9927, 'grad_norm': 0.49561816453933716, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "{'loss': 2.9919, 'grad_norm': 0.5130966305732727, 'learning_rate': 0.00019954545454545455, 'epoch': 0.24}\n",
      "{'loss': 2.3785, 'grad_norm': 0.3576299846172333, 'learning_rate': 0.0001990909090909091, 'epoch': 0.27}\n",
      "{'loss': 2.3285, 'grad_norm': 0.3643341362476349, 'learning_rate': 0.00019863636363636364, 'epoch': 0.29}\n",
      "{'loss': 2.2773, 'grad_norm': 0.3570943772792816, 'learning_rate': 0.00019818181818181821, 'epoch': 0.31}\n",
      "{'loss': 2.3198, 'grad_norm': 0.37088409066200256, 'learning_rate': 0.00019772727272727273, 'epoch': 0.33}\n",
      "{'loss': 2.3805, 'grad_norm': 0.3637697398662567, 'learning_rate': 0.00019727272727272728, 'epoch': 0.36}\n",
      "{'loss': 2.4751, 'grad_norm': 0.36303552985191345, 'learning_rate': 0.00019681818181818185, 'epoch': 0.38}\n",
      "{'loss': 2.4263, 'grad_norm': 0.3782895803451538, 'learning_rate': 0.00019636363636363636, 'epoch': 0.4}\n",
      "{'loss': 2.4784, 'grad_norm': 0.36471787095069885, 'learning_rate': 0.0001959090909090909, 'epoch': 0.42}\n",
      "{'loss': 2.6414, 'grad_norm': 0.4061623215675354, 'learning_rate': 0.00019545454545454548, 'epoch': 0.44}\n",
      "{'loss': 2.8369, 'grad_norm': 0.4266089200973511, 'learning_rate': 0.000195, 'epoch': 0.47}\n",
      "{'loss': 2.8421, 'grad_norm': 0.41782906651496887, 'learning_rate': 0.00019454545454545457, 'epoch': 0.49}\n",
      "{'loss': 2.162, 'grad_norm': 0.3179257810115814, 'learning_rate': 0.0001940909090909091, 'epoch': 0.51}\n",
      "{'loss': 2.1648, 'grad_norm': 0.31928133964538574, 'learning_rate': 0.00019363636363636363, 'epoch': 0.53}\n",
      "{'loss': 2.1542, 'grad_norm': 0.3116534650325775, 'learning_rate': 0.0001931818181818182, 'epoch': 0.56}\n",
      "{'loss': 2.2391, 'grad_norm': 0.3255630433559418, 'learning_rate': 0.00019272727272727274, 'epoch': 0.58}\n",
      "{'loss': 2.1997, 'grad_norm': 0.3134244382381439, 'learning_rate': 0.00019227272727272726, 'epoch': 0.6}\n",
      "{'loss': 2.2363, 'grad_norm': 0.3178441524505615, 'learning_rate': 0.00019181818181818183, 'epoch': 0.62}\n",
      "{'loss': 2.3469, 'grad_norm': 0.3286835849285126, 'learning_rate': 0.00019136363636363638, 'epoch': 0.64}\n",
      "{'loss': 2.5694, 'grad_norm': 0.35189488530158997, 'learning_rate': 0.00019090909090909092, 'epoch': 0.67}\n",
      "{'loss': 2.8125, 'grad_norm': 0.40849828720092773, 'learning_rate': 0.00019045454545454547, 'epoch': 0.69}\n",
      "{'loss': 2.7368, 'grad_norm': 0.3799954056739807, 'learning_rate': 0.00019, 'epoch': 0.71}\n",
      "{'loss': 2.6854, 'grad_norm': 0.3803175091743469, 'learning_rate': 0.00018954545454545455, 'epoch': 0.73}\n",
      "{'loss': 2.0992, 'grad_norm': 0.275137335062027, 'learning_rate': 0.0001890909090909091, 'epoch': 0.76}\n",
      "{'loss': 2.0352, 'grad_norm': 0.27623432874679565, 'learning_rate': 0.00018863636363636364, 'epoch': 0.78}\n",
      "{'loss': 2.1007, 'grad_norm': 0.27149155735969543, 'learning_rate': 0.0001881818181818182, 'epoch': 0.8}\n",
      "{'loss': 2.0739, 'grad_norm': 0.2619381248950958, 'learning_rate': 0.00018772727272727273, 'epoch': 0.82}\n",
      "{'loss': 2.066, 'grad_norm': 0.26906517148017883, 'learning_rate': 0.00018727272727272728, 'epoch': 0.84}\n",
      "{'loss': 2.1578, 'grad_norm': 0.2698463499546051, 'learning_rate': 0.00018681818181818182, 'epoch': 0.87}\n",
      "{'loss': 2.1591, 'grad_norm': 0.277575820684433, 'learning_rate': 0.00018636363636363636, 'epoch': 0.89}\n",
      "{'loss': 2.1573, 'grad_norm': 0.26972487568855286, 'learning_rate': 0.0001859090909090909, 'epoch': 0.91}\n",
      "{'loss': 2.2619, 'grad_norm': 0.2810400426387787, 'learning_rate': 0.00018545454545454545, 'epoch': 0.93}\n",
      "{'loss': 2.3788, 'grad_norm': 0.30737069249153137, 'learning_rate': 0.00018500000000000002, 'epoch': 0.96}\n",
      "{'loss': 2.6036, 'grad_norm': 0.3409113883972168, 'learning_rate': 0.00018454545454545454, 'epoch': 0.98}\n",
      "{'loss': 2.1805, 'grad_norm': 0.2730082869529724, 'learning_rate': 0.00018409090909090909, 'epoch': 1.0}\n",
      "{'loss': 2.0352, 'grad_norm': 0.24850896000862122, 'learning_rate': 0.00018363636363636366, 'epoch': 1.02}\n",
      "{'loss': 2.0917, 'grad_norm': 0.2592095136642456, 'learning_rate': 0.00018318181818181817, 'epoch': 1.04}\n",
      "{'loss': 2.0933, 'grad_norm': 0.25344690680503845, 'learning_rate': 0.00018272727272727275, 'epoch': 1.07}\n",
      "{'loss': 1.9974, 'grad_norm': 0.24668599665164948, 'learning_rate': 0.0001822727272727273, 'epoch': 1.09}\n",
      "{'loss': 2.0505, 'grad_norm': 0.2539641857147217, 'learning_rate': 0.00018181818181818183, 'epoch': 1.11}\n",
      "{'loss': 2.0622, 'grad_norm': 0.2546512186527252, 'learning_rate': 0.00018136363636363638, 'epoch': 1.13}\n",
      "{'loss': 2.1115, 'grad_norm': 0.25304731726646423, 'learning_rate': 0.00018090909090909092, 'epoch': 1.16}\n",
      "{'loss': 2.2034, 'grad_norm': 0.26607808470726013, 'learning_rate': 0.00018045454545454547, 'epoch': 1.18}\n",
      "{'loss': 2.1987, 'grad_norm': 0.2782769799232483, 'learning_rate': 0.00018, 'epoch': 1.2}\n",
      "{'loss': 2.5502, 'grad_norm': 0.32478249073028564, 'learning_rate': 0.00017954545454545456, 'epoch': 1.22}\n",
      "{'loss': 2.5252, 'grad_norm': 0.3262016773223877, 'learning_rate': 0.0001790909090909091, 'epoch': 1.24}\n",
      "{'loss': 1.888, 'grad_norm': 0.22626398503780365, 'learning_rate': 0.00017863636363636364, 'epoch': 1.27}\n",
      "{'loss': 1.8848, 'grad_norm': 0.23341451585292816, 'learning_rate': 0.0001781818181818182, 'epoch': 1.29}\n",
      "{'loss': 2.0284, 'grad_norm': 0.2417209893465042, 'learning_rate': 0.00017772727272727273, 'epoch': 1.31}\n",
      "{'loss': 1.9784, 'grad_norm': 0.25391608476638794, 'learning_rate': 0.00017727272727272728, 'epoch': 1.33}\n",
      "{'loss': 2.0138, 'grad_norm': 0.2460053712129593, 'learning_rate': 0.00017681818181818182, 'epoch': 1.36}\n",
      "{'loss': 2.0679, 'grad_norm': 0.2521651089191437, 'learning_rate': 0.00017636363636363637, 'epoch': 1.38}\n",
      "{'loss': 2.1836, 'grad_norm': 0.26132792234420776, 'learning_rate': 0.0001759090909090909, 'epoch': 1.4}\n",
      "{'loss': 2.192, 'grad_norm': 0.2743401527404785, 'learning_rate': 0.00017545454545454548, 'epoch': 1.42}\n",
      "{'loss': 2.3459, 'grad_norm': 0.28868675231933594, 'learning_rate': 0.000175, 'epoch': 1.44}\n",
      "{'loss': 2.4896, 'grad_norm': 0.30675825476646423, 'learning_rate': 0.00017454545454545454, 'epoch': 1.47}\n",
      "{'loss': 2.4467, 'grad_norm': 0.30856430530548096, 'learning_rate': 0.00017409090909090911, 'epoch': 1.49}\n",
      "{'loss': 1.8596, 'grad_norm': 0.2266489863395691, 'learning_rate': 0.00017363636363636363, 'epoch': 1.51}\n",
      "{'loss': 1.8902, 'grad_norm': 0.23440396785736084, 'learning_rate': 0.0001731818181818182, 'epoch': 1.53}\n",
      "{'loss': 1.9935, 'grad_norm': 0.2324540764093399, 'learning_rate': 0.00017272727272727275, 'epoch': 1.56}\n",
      "{'loss': 1.9245, 'grad_norm': 0.23270823061466217, 'learning_rate': 0.00017227272727272726, 'epoch': 1.58}\n",
      "{'loss': 1.9158, 'grad_norm': 0.23543262481689453, 'learning_rate': 0.00017181818181818184, 'epoch': 1.6}\n",
      "{'loss': 1.9632, 'grad_norm': 0.23371371626853943, 'learning_rate': 0.00017136363636363638, 'epoch': 1.62}\n",
      "{'loss': 2.067, 'grad_norm': 0.25083959102630615, 'learning_rate': 0.0001709090909090909, 'epoch': 1.64}\n",
      "{'loss': 2.0351, 'grad_norm': 0.252798467874527, 'learning_rate': 0.00017045454545454547, 'epoch': 1.67}\n",
      "{'loss': 2.2689, 'grad_norm': 0.2812902629375458, 'learning_rate': 0.00017, 'epoch': 1.69}\n",
      "{'loss': 2.4179, 'grad_norm': 0.2922610342502594, 'learning_rate': 0.00016954545454545456, 'epoch': 1.71}\n",
      "{'loss': 2.3778, 'grad_norm': 0.3080481290817261, 'learning_rate': 0.0001690909090909091, 'epoch': 1.73}\n",
      "{'loss': 1.8408, 'grad_norm': 0.2219080626964569, 'learning_rate': 0.00016863636363636364, 'epoch': 1.76}\n",
      "{'loss': 1.9044, 'grad_norm': 0.22526492178440094, 'learning_rate': 0.0001681818181818182, 'epoch': 1.78}\n",
      "{'loss': 1.909, 'grad_norm': 0.2348879724740982, 'learning_rate': 0.00016772727272727273, 'epoch': 1.8}\n",
      "{'loss': 1.9457, 'grad_norm': 0.23599621653556824, 'learning_rate': 0.00016727272727272728, 'epoch': 1.82}\n",
      "{'loss': 1.9844, 'grad_norm': 0.2353115826845169, 'learning_rate': 0.00016681818181818182, 'epoch': 1.84}\n",
      "{'loss': 1.9327, 'grad_norm': 0.23820829391479492, 'learning_rate': 0.00016636363636363637, 'epoch': 1.87}\n",
      "{'loss': 2.064, 'grad_norm': 0.24394559860229492, 'learning_rate': 0.00016590909090909094, 'epoch': 1.89}\n",
      "{'loss': 2.0407, 'grad_norm': 0.24994134902954102, 'learning_rate': 0.00016545454545454545, 'epoch': 1.91}\n",
      "{'loss': 2.2254, 'grad_norm': 0.28391626477241516, 'learning_rate': 0.000165, 'epoch': 1.93}\n",
      "{'loss': 2.3578, 'grad_norm': 0.2956773042678833, 'learning_rate': 0.00016454545454545457, 'epoch': 1.96}\n",
      "{'loss': 2.3412, 'grad_norm': 0.30546271800994873, 'learning_rate': 0.0001640909090909091, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8271, 'grad_norm': 0.2228698581457138, 'learning_rate': 0.00016363636363636366, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5120cc9374a6441c8c138ae19c3a142f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.105137586593628, 'eval_runtime': 1.0733, 'eval_samples_per_second': 9.317, 'eval_steps_per_second': 9.317, 'epoch': 2.0}\n",
      "{'loss': 1.7905, 'grad_norm': 0.20809856057167053, 'learning_rate': 0.0001631818181818182, 'epoch': 2.02}\n",
      "{'loss': 1.8256, 'grad_norm': 0.222058966755867, 'learning_rate': 0.00016272727272727272, 'epoch': 2.04}\n",
      "{'loss': 1.8, 'grad_norm': 0.21095602214336395, 'learning_rate': 0.0001622727272727273, 'epoch': 2.07}\n",
      "{'loss': 1.873, 'grad_norm': 0.21737197041511536, 'learning_rate': 0.00016181818181818184, 'epoch': 2.09}\n",
      "{'loss': 1.8057, 'grad_norm': 0.2232443392276764, 'learning_rate': 0.00016136363636363635, 'epoch': 2.11}\n",
      "{'loss': 1.8031, 'grad_norm': 0.22281919419765472, 'learning_rate': 0.00016090909090909092, 'epoch': 2.13}\n",
      "{'loss': 1.8679, 'grad_norm': 0.23071524500846863, 'learning_rate': 0.00016045454545454547, 'epoch': 2.16}\n",
      "{'loss': 1.9032, 'grad_norm': 0.25060176849365234, 'learning_rate': 0.00016, 'epoch': 2.18}\n",
      "{'loss': 2.0797, 'grad_norm': 0.24426884949207306, 'learning_rate': 0.00015954545454545456, 'epoch': 2.2}\n",
      "{'loss': 1.9132, 'grad_norm': 0.24213699996471405, 'learning_rate': 0.0001590909090909091, 'epoch': 2.22}\n",
      "{'loss': 2.218, 'grad_norm': 0.2953898310661316, 'learning_rate': 0.00015863636363636365, 'epoch': 2.24}\n",
      "{'loss': 1.7673, 'grad_norm': 0.21495307981967926, 'learning_rate': 0.0001581818181818182, 'epoch': 2.27}\n",
      "{'loss': 1.8234, 'grad_norm': 0.2320794314146042, 'learning_rate': 0.00015772727272727273, 'epoch': 2.29}\n",
      "{'loss': 1.7834, 'grad_norm': 0.2302464246749878, 'learning_rate': 0.00015727272727272728, 'epoch': 2.31}\n",
      "{'loss': 1.8071, 'grad_norm': 0.2281925529241562, 'learning_rate': 0.00015681818181818182, 'epoch': 2.33}\n",
      "{'loss': 1.8575, 'grad_norm': 0.2361246794462204, 'learning_rate': 0.00015636363636363637, 'epoch': 2.36}\n",
      "{'loss': 1.9062, 'grad_norm': 0.2556605935096741, 'learning_rate': 0.0001559090909090909, 'epoch': 2.38}\n",
      "{'loss': 2.0997, 'grad_norm': 0.268771231174469, 'learning_rate': 0.00015545454545454546, 'epoch': 2.4}\n",
      "{'loss': 2.1465, 'grad_norm': 0.28240707516670227, 'learning_rate': 0.000155, 'epoch': 2.42}\n",
      "{'loss': 2.2344, 'grad_norm': 0.29531142115592957, 'learning_rate': 0.00015454545454545454, 'epoch': 2.44}\n",
      "{'loss': 2.2215, 'grad_norm': 0.2996518909931183, 'learning_rate': 0.00015409090909090912, 'epoch': 2.47}\n",
      "{'loss': 2.1368, 'grad_norm': 0.3010975122451782, 'learning_rate': 0.00015363636363636363, 'epoch': 2.49}\n",
      "{'loss': 1.6922, 'grad_norm': 0.2056904435157776, 'learning_rate': 0.00015318181818181818, 'epoch': 2.51}\n",
      "{'loss': 1.6611, 'grad_norm': 0.22542749345302582, 'learning_rate': 0.00015272727272727275, 'epoch': 2.53}\n",
      "{'loss': 1.7242, 'grad_norm': 0.2107757329940796, 'learning_rate': 0.00015227272727272727, 'epoch': 2.56}\n",
      "{'loss': 1.7073, 'grad_norm': 0.2285684496164322, 'learning_rate': 0.0001518181818181818, 'epoch': 2.58}\n",
      "{'loss': 1.7664, 'grad_norm': 0.22895556688308716, 'learning_rate': 0.00015136363636363638, 'epoch': 2.6}\n",
      "{'loss': 1.7636, 'grad_norm': 0.24168217182159424, 'learning_rate': 0.0001509090909090909, 'epoch': 2.62}\n",
      "{'loss': 1.7747, 'grad_norm': 0.23611456155776978, 'learning_rate': 0.00015045454545454547, 'epoch': 2.64}\n",
      "{'loss': 1.788, 'grad_norm': 0.24761955440044403, 'learning_rate': 0.00015000000000000001, 'epoch': 2.67}\n",
      "{'loss': 1.8963, 'grad_norm': 0.2486490160226822, 'learning_rate': 0.00014954545454545453, 'epoch': 2.69}\n",
      "{'loss': 2.2006, 'grad_norm': 0.2965131998062134, 'learning_rate': 0.0001490909090909091, 'epoch': 2.71}\n",
      "{'loss': 2.1281, 'grad_norm': 0.2979056239128113, 'learning_rate': 0.00014863636363636365, 'epoch': 2.73}\n",
      "{'loss': 1.6282, 'grad_norm': 0.21579605340957642, 'learning_rate': 0.0001481818181818182, 'epoch': 2.76}\n",
      "{'loss': 1.6382, 'grad_norm': 0.20019429922103882, 'learning_rate': 0.00014772727272727274, 'epoch': 2.78}\n",
      "{'loss': 1.6528, 'grad_norm': 0.220209538936615, 'learning_rate': 0.00014727272727272728, 'epoch': 2.8}\n",
      "{'loss': 1.6396, 'grad_norm': 0.20189383625984192, 'learning_rate': 0.00014681818181818182, 'epoch': 2.82}\n",
      "{'loss': 1.685, 'grad_norm': 0.21762189269065857, 'learning_rate': 0.00014636363636363637, 'epoch': 2.84}\n",
      "{'loss': 1.6581, 'grad_norm': 0.2234034687280655, 'learning_rate': 0.0001459090909090909, 'epoch': 2.87}\n",
      "{'loss': 1.7076, 'grad_norm': 0.21251633763313293, 'learning_rate': 0.00014545454545454546, 'epoch': 2.89}\n",
      "{'loss': 1.7973, 'grad_norm': 0.235316202044487, 'learning_rate': 0.000145, 'epoch': 2.91}\n",
      "{'loss': 1.9614, 'grad_norm': 0.2702578604221344, 'learning_rate': 0.00014454545454545457, 'epoch': 2.93}\n",
      "{'loss': 2.0499, 'grad_norm': 0.2685401439666748, 'learning_rate': 0.0001440909090909091, 'epoch': 2.96}\n",
      "{'loss': 2.0651, 'grad_norm': 0.2961002290248871, 'learning_rate': 0.00014363636363636363, 'epoch': 2.98}\n",
      "{'loss': 1.8501, 'grad_norm': 0.2361690104007721, 'learning_rate': 0.0001431818181818182, 'epoch': 3.0}\n",
      "{'loss': 1.6106, 'grad_norm': 0.21087145805358887, 'learning_rate': 0.00014272727272727272, 'epoch': 3.02}\n",
      "{'loss': 1.6118, 'grad_norm': 0.21994024515151978, 'learning_rate': 0.00014227272727272727, 'epoch': 3.04}\n",
      "{'loss': 1.5698, 'grad_norm': 0.2117740660905838, 'learning_rate': 0.00014181818181818184, 'epoch': 3.07}\n",
      "{'loss': 1.654, 'grad_norm': 0.20588746666908264, 'learning_rate': 0.00014136363636363635, 'epoch': 3.09}\n",
      "{'loss': 1.6451, 'grad_norm': 0.21215605735778809, 'learning_rate': 0.00014090909090909093, 'epoch': 3.11}\n",
      "{'loss': 1.682, 'grad_norm': 0.21123650670051575, 'learning_rate': 0.00014045454545454547, 'epoch': 3.13}\n",
      "{'loss': 1.686, 'grad_norm': 0.2372279316186905, 'learning_rate': 0.00014, 'epoch': 3.16}\n",
      "{'loss': 1.7359, 'grad_norm': 0.23454996943473816, 'learning_rate': 0.00013954545454545456, 'epoch': 3.18}\n",
      "{'loss': 2.0675, 'grad_norm': 0.2847174406051636, 'learning_rate': 0.0001390909090909091, 'epoch': 3.2}\n",
      "{'loss': 2.0024, 'grad_norm': 0.2911323606967926, 'learning_rate': 0.00013863636363636365, 'epoch': 3.22}\n",
      "{'loss': 1.9763, 'grad_norm': 0.2974121868610382, 'learning_rate': 0.0001381818181818182, 'epoch': 3.24}\n",
      "{'loss': 1.6117, 'grad_norm': 0.20607317984104156, 'learning_rate': 0.00013772727272727274, 'epoch': 3.27}\n",
      "{'loss': 1.5238, 'grad_norm': 0.21519100666046143, 'learning_rate': 0.00013727272727272728, 'epoch': 3.29}\n",
      "{'loss': 1.5958, 'grad_norm': 0.19760777056217194, 'learning_rate': 0.00013681818181818182, 'epoch': 3.31}\n",
      "{'loss': 1.6437, 'grad_norm': 0.21427813172340393, 'learning_rate': 0.00013636363636363637, 'epoch': 3.33}\n",
      "{'loss': 1.5441, 'grad_norm': 0.21339835226535797, 'learning_rate': 0.0001359090909090909, 'epoch': 3.36}\n",
      "{'loss': 1.6251, 'grad_norm': 0.21751828491687775, 'learning_rate': 0.00013545454545454546, 'epoch': 3.38}\n",
      "{'loss': 1.6592, 'grad_norm': 0.23689180612564087, 'learning_rate': 0.00013500000000000003, 'epoch': 3.4}\n",
      "{'loss': 1.6811, 'grad_norm': 0.24275006353855133, 'learning_rate': 0.00013454545454545455, 'epoch': 3.42}\n",
      "{'loss': 1.7921, 'grad_norm': 0.24518625438213348, 'learning_rate': 0.0001340909090909091, 'epoch': 3.44}\n",
      "{'loss': 1.9126, 'grad_norm': 0.27552250027656555, 'learning_rate': 0.00013363636363636366, 'epoch': 3.47}\n",
      "{'loss': 1.986, 'grad_norm': 0.2929888069629669, 'learning_rate': 0.00013318181818181818, 'epoch': 3.49}\n",
      "{'loss': 1.498, 'grad_norm': 0.20831362903118134, 'learning_rate': 0.00013272727272727275, 'epoch': 3.51}\n",
      "{'loss': 1.5602, 'grad_norm': 0.21531297266483307, 'learning_rate': 0.0001322727272727273, 'epoch': 3.53}\n",
      "{'loss': 1.5919, 'grad_norm': 0.22260862588882446, 'learning_rate': 0.0001318181818181818, 'epoch': 3.56}\n",
      "{'loss': 1.5516, 'grad_norm': 0.22814112901687622, 'learning_rate': 0.00013136363636363638, 'epoch': 3.58}\n",
      "{'loss': 1.5817, 'grad_norm': 0.22651644051074982, 'learning_rate': 0.00013090909090909093, 'epoch': 3.6}\n",
      "{'loss': 1.5837, 'grad_norm': 0.23657777905464172, 'learning_rate': 0.00013045454545454544, 'epoch': 3.62}\n",
      "{'loss': 1.5594, 'grad_norm': 0.21954727172851562, 'learning_rate': 0.00013000000000000002, 'epoch': 3.64}\n",
      "{'loss': 1.6123, 'grad_norm': 0.24550019204616547, 'learning_rate': 0.00012954545454545456, 'epoch': 3.67}\n",
      "{'loss': 1.8008, 'grad_norm': 0.25527745485305786, 'learning_rate': 0.0001290909090909091, 'epoch': 3.69}\n",
      "{'loss': 1.8972, 'grad_norm': 0.2686809301376343, 'learning_rate': 0.00012863636363636365, 'epoch': 3.71}\n",
      "{'loss': 1.9074, 'grad_norm': 0.29493337869644165, 'learning_rate': 0.0001281818181818182, 'epoch': 3.73}\n",
      "{'loss': 1.5102, 'grad_norm': 0.20367664098739624, 'learning_rate': 0.00012772727272727274, 'epoch': 3.76}\n",
      "{'loss': 1.483, 'grad_norm': 0.2137695848941803, 'learning_rate': 0.00012727272727272728, 'epoch': 3.78}\n",
      "{'loss': 1.4816, 'grad_norm': 0.21065528690814972, 'learning_rate': 0.00012681818181818183, 'epoch': 3.8}\n",
      "{'loss': 1.474, 'grad_norm': 0.2121073305606842, 'learning_rate': 0.00012636363636363637, 'epoch': 3.82}\n",
      "{'loss': 1.6143, 'grad_norm': 0.22626982629299164, 'learning_rate': 0.00012590909090909091, 'epoch': 3.84}\n",
      "{'loss': 1.6222, 'grad_norm': 0.24206843972206116, 'learning_rate': 0.00012545454545454546, 'epoch': 3.87}\n",
      "{'loss': 1.6494, 'grad_norm': 0.24284499883651733, 'learning_rate': 0.000125, 'epoch': 3.89}\n",
      "{'loss': 1.7266, 'grad_norm': 0.228044331073761, 'learning_rate': 0.00012454545454545455, 'epoch': 3.91}\n",
      "{'loss': 1.72, 'grad_norm': 0.2684750258922577, 'learning_rate': 0.0001240909090909091, 'epoch': 3.93}\n",
      "{'loss': 1.8903, 'grad_norm': 0.29137247800827026, 'learning_rate': 0.00012363636363636364, 'epoch': 3.96}\n",
      "{'loss': 1.8579, 'grad_norm': 0.30056101083755493, 'learning_rate': 0.0001231818181818182, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4727, 'grad_norm': 0.21479246020317078, 'learning_rate': 0.00012272727272727272, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bc424939494b2eabdb9aae9de9a713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6826480627059937, 'eval_runtime': 1.1005, 'eval_samples_per_second': 9.087, 'eval_steps_per_second': 9.087, 'epoch': 4.0}\n",
      "{'loss': 1.4282, 'grad_norm': 0.20051975548267365, 'learning_rate': 0.00012227272727272727, 'epoch': 4.02}\n",
      "{'loss': 1.4486, 'grad_norm': 0.2088058441877365, 'learning_rate': 0.00012181818181818183, 'epoch': 4.04}\n",
      "{'loss': 1.4804, 'grad_norm': 0.21559588611125946, 'learning_rate': 0.00012136363636363637, 'epoch': 4.07}\n",
      "{'loss': 1.4851, 'grad_norm': 0.20453603565692902, 'learning_rate': 0.0001209090909090909, 'epoch': 4.09}\n",
      "{'loss': 1.4251, 'grad_norm': 0.21104025840759277, 'learning_rate': 0.00012045454545454546, 'epoch': 4.11}\n",
      "{'loss': 1.4937, 'grad_norm': 0.22659382224082947, 'learning_rate': 0.00012, 'epoch': 4.13}\n",
      "{'loss': 1.5521, 'grad_norm': 0.22575554251670837, 'learning_rate': 0.00011954545454545456, 'epoch': 4.16}\n",
      "{'loss': 1.5642, 'grad_norm': 0.2347021847963333, 'learning_rate': 0.00011909090909090909, 'epoch': 4.18}\n",
      "{'loss': 1.7293, 'grad_norm': 0.2702357769012451, 'learning_rate': 0.00011863636363636364, 'epoch': 4.2}\n",
      "{'loss': 1.8236, 'grad_norm': 0.2736082673072815, 'learning_rate': 0.0001181818181818182, 'epoch': 4.22}\n",
      "{'loss': 1.8644, 'grad_norm': 0.2886124849319458, 'learning_rate': 0.00011772727272727272, 'epoch': 4.24}\n",
      "{'loss': 1.4147, 'grad_norm': 0.2089347094297409, 'learning_rate': 0.00011727272727272727, 'epoch': 4.27}\n",
      "{'loss': 1.4157, 'grad_norm': 0.20690669119358063, 'learning_rate': 0.00011681818181818183, 'epoch': 4.29}\n",
      "{'loss': 1.4864, 'grad_norm': 0.2195650339126587, 'learning_rate': 0.00011636363636363636, 'epoch': 4.31}\n",
      "{'loss': 1.4441, 'grad_norm': 0.21858513355255127, 'learning_rate': 0.00011590909090909093, 'epoch': 4.33}\n",
      "{'loss': 1.4566, 'grad_norm': 0.20332831144332886, 'learning_rate': 0.00011545454545454546, 'epoch': 4.36}\n",
      "{'loss': 1.4747, 'grad_norm': 0.2190786749124527, 'learning_rate': 0.00011499999999999999, 'epoch': 4.38}\n",
      "{'loss': 1.5154, 'grad_norm': 0.23012347519397736, 'learning_rate': 0.00011454545454545456, 'epoch': 4.4}\n",
      "{'loss': 1.499, 'grad_norm': 0.23120233416557312, 'learning_rate': 0.00011409090909090909, 'epoch': 4.42}\n",
      "{'loss': 1.4955, 'grad_norm': 0.23461057245731354, 'learning_rate': 0.00011363636363636365, 'epoch': 4.44}\n",
      "{'loss': 1.7962, 'grad_norm': 0.2788431644439697, 'learning_rate': 0.0001131818181818182, 'epoch': 4.47}\n",
      "{'loss': 1.7083, 'grad_norm': 0.26010292768478394, 'learning_rate': 0.00011272727272727272, 'epoch': 4.49}\n",
      "{'loss': 1.4095, 'grad_norm': 0.22318945825099945, 'learning_rate': 0.00011227272727272728, 'epoch': 4.51}\n",
      "{'loss': 1.3927, 'grad_norm': 0.21418358385562897, 'learning_rate': 0.00011181818181818183, 'epoch': 4.53}\n",
      "{'loss': 1.3913, 'grad_norm': 0.19745111465454102, 'learning_rate': 0.00011136363636363636, 'epoch': 4.56}\n",
      "{'loss': 1.3989, 'grad_norm': 0.20030729472637177, 'learning_rate': 0.00011090909090909092, 'epoch': 4.58}\n",
      "{'loss': 1.3857, 'grad_norm': 0.19354072213172913, 'learning_rate': 0.00011045454545454546, 'epoch': 4.6}\n",
      "{'loss': 1.4257, 'grad_norm': 0.21082863211631775, 'learning_rate': 0.00011000000000000002, 'epoch': 4.62}\n",
      "{'loss': 1.4042, 'grad_norm': 0.20603898167610168, 'learning_rate': 0.00010954545454545455, 'epoch': 4.64}\n",
      "{'loss': 1.6107, 'grad_norm': 0.22047699987888336, 'learning_rate': 0.00010909090909090909, 'epoch': 4.67}\n",
      "{'loss': 1.4501, 'grad_norm': 0.22997789084911346, 'learning_rate': 0.00010863636363636365, 'epoch': 4.69}\n",
      "{'loss': 1.7615, 'grad_norm': 0.27938005328178406, 'learning_rate': 0.00010818181818181818, 'epoch': 4.71}\n",
      "{'loss': 1.7053, 'grad_norm': 0.2895348072052002, 'learning_rate': 0.00010772727272727274, 'epoch': 4.73}\n",
      "{'loss': 1.3228, 'grad_norm': 0.19676151871681213, 'learning_rate': 0.00010727272727272728, 'epoch': 4.76}\n",
      "{'loss': 1.4107, 'grad_norm': 0.19998599588871002, 'learning_rate': 0.00010681818181818181, 'epoch': 4.78}\n",
      "{'loss': 1.3099, 'grad_norm': 0.2088698297739029, 'learning_rate': 0.00010636363636363637, 'epoch': 4.8}\n",
      "{'loss': 1.4895, 'grad_norm': 0.2241245061159134, 'learning_rate': 0.00010590909090909092, 'epoch': 4.82}\n",
      "{'loss': 1.3482, 'grad_norm': 0.1947825402021408, 'learning_rate': 0.00010545454545454545, 'epoch': 4.84}\n",
      "{'loss': 1.4054, 'grad_norm': 0.21859943866729736, 'learning_rate': 0.000105, 'epoch': 4.87}\n",
      "{'loss': 1.5428, 'grad_norm': 0.2434178739786148, 'learning_rate': 0.00010454545454545455, 'epoch': 4.89}\n",
      "{'loss': 1.4927, 'grad_norm': 0.23032717406749725, 'learning_rate': 0.0001040909090909091, 'epoch': 4.91}\n",
      "{'loss': 1.6768, 'grad_norm': 0.2631091773509979, 'learning_rate': 0.00010363636363636364, 'epoch': 4.93}\n",
      "{'loss': 1.667, 'grad_norm': 0.2880270183086395, 'learning_rate': 0.00010318181818181818, 'epoch': 4.96}\n",
      "{'loss': 1.67, 'grad_norm': 0.2798311114311218, 'learning_rate': 0.00010272727272727274, 'epoch': 4.98}\n",
      "{'loss': 1.5068, 'grad_norm': 0.22922354936599731, 'learning_rate': 0.00010227272727272727, 'epoch': 5.0}\n",
      "{'loss': 1.3444, 'grad_norm': 0.21123415231704712, 'learning_rate': 0.00010181818181818181, 'epoch': 5.02}\n",
      "{'loss': 1.2875, 'grad_norm': 0.21557489037513733, 'learning_rate': 0.00010136363636363637, 'epoch': 5.04}\n",
      "{'loss': 1.3454, 'grad_norm': 0.2015056312084198, 'learning_rate': 0.0001009090909090909, 'epoch': 5.07}\n",
      "{'loss': 1.3715, 'grad_norm': 0.21826955676078796, 'learning_rate': 0.00010045454545454547, 'epoch': 5.09}\n",
      "{'loss': 1.3476, 'grad_norm': 0.20424240827560425, 'learning_rate': 0.0001, 'epoch': 5.11}\n",
      "{'loss': 1.3808, 'grad_norm': 0.1997653692960739, 'learning_rate': 9.954545454545455e-05, 'epoch': 5.13}\n",
      "{'loss': 1.4667, 'grad_norm': 0.24077002704143524, 'learning_rate': 9.909090909090911e-05, 'epoch': 5.16}\n",
      "{'loss': 1.4067, 'grad_norm': 0.22601905465126038, 'learning_rate': 9.863636363636364e-05, 'epoch': 5.18}\n",
      "{'loss': 1.6832, 'grad_norm': 0.2829940915107727, 'learning_rate': 9.818181818181818e-05, 'epoch': 5.2}\n",
      "{'loss': 1.7103, 'grad_norm': 0.30023500323295593, 'learning_rate': 9.772727272727274e-05, 'epoch': 5.22}\n",
      "{'loss': 1.6012, 'grad_norm': 0.2575716972351074, 'learning_rate': 9.727272727272728e-05, 'epoch': 5.24}\n",
      "{'loss': 1.3606, 'grad_norm': 0.20201432704925537, 'learning_rate': 9.681818181818181e-05, 'epoch': 5.27}\n",
      "{'loss': 1.2788, 'grad_norm': 0.20204585790634155, 'learning_rate': 9.636363636363637e-05, 'epoch': 5.29}\n",
      "{'loss': 1.2998, 'grad_norm': 0.21506328880786896, 'learning_rate': 9.590909090909092e-05, 'epoch': 5.31}\n",
      "{'loss': 1.3304, 'grad_norm': 0.2169249802827835, 'learning_rate': 9.545454545454546e-05, 'epoch': 5.33}\n",
      "{'loss': 1.3218, 'grad_norm': 0.2129976749420166, 'learning_rate': 9.5e-05, 'epoch': 5.36}\n",
      "{'loss': 1.3682, 'grad_norm': 0.21900124847888947, 'learning_rate': 9.454545454545455e-05, 'epoch': 5.38}\n",
      "{'loss': 1.3511, 'grad_norm': 0.24871474504470825, 'learning_rate': 9.40909090909091e-05, 'epoch': 5.4}\n",
      "{'loss': 1.3813, 'grad_norm': 0.2331261932849884, 'learning_rate': 9.363636363636364e-05, 'epoch': 5.42}\n",
      "{'loss': 1.4434, 'grad_norm': 0.241805300116539, 'learning_rate': 9.318181818181818e-05, 'epoch': 5.44}\n",
      "{'loss': 1.5841, 'grad_norm': 0.28509917855262756, 'learning_rate': 9.272727272727273e-05, 'epoch': 5.47}\n",
      "{'loss': 1.5742, 'grad_norm': 0.2850455343723297, 'learning_rate': 9.227272727272727e-05, 'epoch': 5.49}\n",
      "{'loss': 1.1975, 'grad_norm': 0.203795924782753, 'learning_rate': 9.181818181818183e-05, 'epoch': 5.51}\n",
      "{'loss': 1.3036, 'grad_norm': 0.1990348845720291, 'learning_rate': 9.136363636363637e-05, 'epoch': 5.53}\n",
      "{'loss': 1.2967, 'grad_norm': 0.21686428785324097, 'learning_rate': 9.090909090909092e-05, 'epoch': 5.56}\n",
      "{'loss': 1.2467, 'grad_norm': 0.19515514373779297, 'learning_rate': 9.045454545454546e-05, 'epoch': 5.58}\n",
      "{'loss': 1.3081, 'grad_norm': 0.2106410413980484, 'learning_rate': 9e-05, 'epoch': 5.6}\n",
      "{'loss': 1.3658, 'grad_norm': 0.21972079575061798, 'learning_rate': 8.954545454545455e-05, 'epoch': 5.62}\n",
      "{'loss': 1.3045, 'grad_norm': 0.22619196772575378, 'learning_rate': 8.90909090909091e-05, 'epoch': 5.64}\n",
      "{'loss': 1.402, 'grad_norm': 0.24174390733242035, 'learning_rate': 8.863636363636364e-05, 'epoch': 5.67}\n",
      "{'loss': 1.4971, 'grad_norm': 0.25755774974823, 'learning_rate': 8.818181818181818e-05, 'epoch': 5.69}\n",
      "{'loss': 1.5943, 'grad_norm': 0.29386022686958313, 'learning_rate': 8.772727272727274e-05, 'epoch': 5.71}\n",
      "{'loss': 1.5376, 'grad_norm': 0.27862870693206787, 'learning_rate': 8.727272727272727e-05, 'epoch': 5.73}\n",
      "{'loss': 1.255, 'grad_norm': 0.19825968146324158, 'learning_rate': 8.681818181818182e-05, 'epoch': 5.76}\n",
      "{'loss': 1.266, 'grad_norm': 0.2032831907272339, 'learning_rate': 8.636363636363637e-05, 'epoch': 5.78}\n",
      "{'loss': 1.2071, 'grad_norm': 0.216597780585289, 'learning_rate': 8.590909090909092e-05, 'epoch': 5.8}\n",
      "{'loss': 1.3186, 'grad_norm': 0.23007598519325256, 'learning_rate': 8.545454545454545e-05, 'epoch': 5.82}\n",
      "{'loss': 1.2812, 'grad_norm': 0.2070956528186798, 'learning_rate': 8.5e-05, 'epoch': 5.84}\n",
      "{'loss': 1.2393, 'grad_norm': 0.21303731203079224, 'learning_rate': 8.454545454545455e-05, 'epoch': 5.87}\n",
      "{'loss': 1.2249, 'grad_norm': 0.23891568183898926, 'learning_rate': 8.40909090909091e-05, 'epoch': 5.89}\n",
      "{'loss': 1.3376, 'grad_norm': 0.23981046676635742, 'learning_rate': 8.363636363636364e-05, 'epoch': 5.91}\n",
      "{'loss': 1.325, 'grad_norm': 0.22323653101921082, 'learning_rate': 8.318181818181818e-05, 'epoch': 5.93}\n",
      "{'loss': 1.5371, 'grad_norm': 0.28632986545562744, 'learning_rate': 8.272727272727273e-05, 'epoch': 5.96}\n",
      "{'loss': 1.5416, 'grad_norm': 0.2741672992706299, 'learning_rate': 8.227272727272729e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3381, 'grad_norm': 0.2087547481060028, 'learning_rate': 8.181818181818183e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1389f91c014135ab1f9712d2c6842b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3890645503997803, 'eval_runtime': 1.0977, 'eval_samples_per_second': 9.11, 'eval_steps_per_second': 9.11, 'epoch': 6.0}\n",
      "{'loss': 1.2349, 'grad_norm': 0.21409077942371368, 'learning_rate': 8.136363636363636e-05, 'epoch': 6.02}\n",
      "{'loss': 1.2512, 'grad_norm': 0.19981037080287933, 'learning_rate': 8.090909090909092e-05, 'epoch': 6.04}\n",
      "{'loss': 1.2578, 'grad_norm': 0.21660538017749786, 'learning_rate': 8.045454545454546e-05, 'epoch': 6.07}\n",
      "{'loss': 1.1741, 'grad_norm': 0.19755034148693085, 'learning_rate': 8e-05, 'epoch': 6.09}\n",
      "{'loss': 1.2039, 'grad_norm': 0.20340712368488312, 'learning_rate': 7.954545454545455e-05, 'epoch': 6.11}\n",
      "{'loss': 1.3123, 'grad_norm': 0.23910517990589142, 'learning_rate': 7.90909090909091e-05, 'epoch': 6.13}\n",
      "{'loss': 1.3935, 'grad_norm': 0.22277049720287323, 'learning_rate': 7.863636363636364e-05, 'epoch': 6.16}\n",
      "{'loss': 1.3878, 'grad_norm': 0.255632221698761, 'learning_rate': 7.818181818181818e-05, 'epoch': 6.18}\n",
      "{'loss': 1.4708, 'grad_norm': 0.26602834463119507, 'learning_rate': 7.772727272727273e-05, 'epoch': 6.2}\n",
      "{'loss': 1.538, 'grad_norm': 0.28272581100463867, 'learning_rate': 7.727272727272727e-05, 'epoch': 6.22}\n",
      "{'loss': 1.5002, 'grad_norm': 0.28650906682014465, 'learning_rate': 7.681818181818182e-05, 'epoch': 6.24}\n",
      "{'loss': 1.1538, 'grad_norm': 0.20812486112117767, 'learning_rate': 7.636363636363637e-05, 'epoch': 6.27}\n",
      "{'loss': 1.2321, 'grad_norm': 0.21819333732128143, 'learning_rate': 7.59090909090909e-05, 'epoch': 6.29}\n",
      "{'loss': 1.2221, 'grad_norm': 0.21724671125411987, 'learning_rate': 7.545454545454545e-05, 'epoch': 6.31}\n",
      "{'loss': 1.1532, 'grad_norm': 0.2153354287147522, 'learning_rate': 7.500000000000001e-05, 'epoch': 6.33}\n",
      "{'loss': 1.2393, 'grad_norm': 0.22121089696884155, 'learning_rate': 7.454545454545455e-05, 'epoch': 6.36}\n",
      "{'loss': 1.2481, 'grad_norm': 0.19834685325622559, 'learning_rate': 7.40909090909091e-05, 'epoch': 6.38}\n",
      "{'loss': 1.2102, 'grad_norm': 0.24720659852027893, 'learning_rate': 7.363636363636364e-05, 'epoch': 6.4}\n",
      "{'loss': 1.2102, 'grad_norm': 0.2279457300901413, 'learning_rate': 7.318181818181818e-05, 'epoch': 6.42}\n",
      "{'loss': 1.3368, 'grad_norm': 0.2331773340702057, 'learning_rate': 7.272727272727273e-05, 'epoch': 6.44}\n",
      "{'loss': 1.5405, 'grad_norm': 0.2821354269981384, 'learning_rate': 7.227272727272729e-05, 'epoch': 6.47}\n",
      "{'loss': 1.3963, 'grad_norm': 0.2529733180999756, 'learning_rate': 7.181818181818182e-05, 'epoch': 6.49}\n",
      "{'loss': 1.1975, 'grad_norm': 0.1983182728290558, 'learning_rate': 7.136363636363636e-05, 'epoch': 6.51}\n",
      "{'loss': 1.1973, 'grad_norm': 0.19936004281044006, 'learning_rate': 7.090909090909092e-05, 'epoch': 6.53}\n",
      "{'loss': 1.2122, 'grad_norm': 0.20459124445915222, 'learning_rate': 7.045454545454546e-05, 'epoch': 6.56}\n",
      "{'loss': 1.1833, 'grad_norm': 0.20812110602855682, 'learning_rate': 7e-05, 'epoch': 6.58}\n",
      "{'loss': 1.2098, 'grad_norm': 0.20759440958499908, 'learning_rate': 6.954545454545455e-05, 'epoch': 6.6}\n",
      "{'loss': 1.1758, 'grad_norm': 0.2128637731075287, 'learning_rate': 6.90909090909091e-05, 'epoch': 6.62}\n",
      "{'loss': 1.2889, 'grad_norm': 0.22345107793807983, 'learning_rate': 6.863636363636364e-05, 'epoch': 6.64}\n",
      "{'loss': 1.176, 'grad_norm': 0.2552790641784668, 'learning_rate': 6.818181818181818e-05, 'epoch': 6.67}\n",
      "{'loss': 1.4667, 'grad_norm': 0.2892877459526062, 'learning_rate': 6.772727272727273e-05, 'epoch': 6.69}\n",
      "{'loss': 1.4076, 'grad_norm': 0.28832098841667175, 'learning_rate': 6.727272727272727e-05, 'epoch': 6.71}\n",
      "{'loss': 1.452, 'grad_norm': 0.3119482100009918, 'learning_rate': 6.681818181818183e-05, 'epoch': 6.73}\n",
      "{'loss': 1.1756, 'grad_norm': 0.21317072212696075, 'learning_rate': 6.636363636363638e-05, 'epoch': 6.76}\n",
      "{'loss': 1.1315, 'grad_norm': 0.20570850372314453, 'learning_rate': 6.59090909090909e-05, 'epoch': 6.78}\n",
      "{'loss': 1.1453, 'grad_norm': 0.18881343305110931, 'learning_rate': 6.545454545454546e-05, 'epoch': 6.8}\n",
      "{'loss': 1.1555, 'grad_norm': 0.19855867326259613, 'learning_rate': 6.500000000000001e-05, 'epoch': 6.82}\n",
      "{'loss': 1.1277, 'grad_norm': 0.22110304236412048, 'learning_rate': 6.454545454545455e-05, 'epoch': 6.84}\n",
      "{'loss': 1.1543, 'grad_norm': 0.20593613386154175, 'learning_rate': 6.40909090909091e-05, 'epoch': 6.87}\n",
      "{'loss': 1.2322, 'grad_norm': 0.21719276905059814, 'learning_rate': 6.363636363636364e-05, 'epoch': 6.89}\n",
      "{'loss': 1.2636, 'grad_norm': 0.2283886820077896, 'learning_rate': 6.318181818181818e-05, 'epoch': 6.91}\n",
      "{'loss': 1.2524, 'grad_norm': 0.2406281977891922, 'learning_rate': 6.272727272727273e-05, 'epoch': 6.93}\n",
      "{'loss': 1.3304, 'grad_norm': 0.2426072359085083, 'learning_rate': 6.227272727272727e-05, 'epoch': 6.96}\n",
      "{'loss': 1.3948, 'grad_norm': 0.2757073938846588, 'learning_rate': 6.181818181818182e-05, 'epoch': 6.98}\n",
      "{'loss': 1.1431, 'grad_norm': 0.2224384844303131, 'learning_rate': 6.136363636363636e-05, 'epoch': 7.0}\n",
      "{'loss': 1.1065, 'grad_norm': 0.20517003536224365, 'learning_rate': 6.090909090909091e-05, 'epoch': 7.02}\n",
      "{'loss': 1.2042, 'grad_norm': 0.22694161534309387, 'learning_rate': 6.045454545454545e-05, 'epoch': 7.04}\n",
      "{'loss': 1.1502, 'grad_norm': 0.21748405694961548, 'learning_rate': 6e-05, 'epoch': 7.07}\n",
      "{'loss': 1.2119, 'grad_norm': 0.21668508648872375, 'learning_rate': 5.9545454545454546e-05, 'epoch': 7.09}\n",
      "{'loss': 1.1183, 'grad_norm': 0.21511895954608917, 'learning_rate': 5.90909090909091e-05, 'epoch': 7.11}\n",
      "{'loss': 1.1771, 'grad_norm': 0.19367657601833344, 'learning_rate': 5.8636363636363634e-05, 'epoch': 7.13}\n",
      "{'loss': 1.1596, 'grad_norm': 0.21948280930519104, 'learning_rate': 5.818181818181818e-05, 'epoch': 7.16}\n",
      "{'loss': 1.209, 'grad_norm': 0.22446082532405853, 'learning_rate': 5.772727272727273e-05, 'epoch': 7.18}\n",
      "{'loss': 1.3628, 'grad_norm': 0.2559505105018616, 'learning_rate': 5.727272727272728e-05, 'epoch': 7.2}\n",
      "{'loss': 1.4316, 'grad_norm': 0.27791088819503784, 'learning_rate': 5.6818181818181825e-05, 'epoch': 7.22}\n",
      "{'loss': 1.37, 'grad_norm': 0.27729150652885437, 'learning_rate': 5.636363636363636e-05, 'epoch': 7.24}\n",
      "{'loss': 1.1322, 'grad_norm': 0.20552687346935272, 'learning_rate': 5.5909090909090913e-05, 'epoch': 7.27}\n",
      "{'loss': 1.0781, 'grad_norm': 0.19864948093891144, 'learning_rate': 5.545454545454546e-05, 'epoch': 7.29}\n",
      "{'loss': 1.1378, 'grad_norm': 0.2131483405828476, 'learning_rate': 5.500000000000001e-05, 'epoch': 7.31}\n",
      "{'loss': 1.1051, 'grad_norm': 0.20568226277828217, 'learning_rate': 5.4545454545454546e-05, 'epoch': 7.33}\n",
      "{'loss': 1.1169, 'grad_norm': 0.2060052752494812, 'learning_rate': 5.409090909090909e-05, 'epoch': 7.36}\n",
      "{'loss': 1.1258, 'grad_norm': 0.19808968901634216, 'learning_rate': 5.363636363636364e-05, 'epoch': 7.38}\n",
      "{'loss': 1.3257, 'grad_norm': 0.2439567744731903, 'learning_rate': 5.3181818181818186e-05, 'epoch': 7.4}\n",
      "{'loss': 1.2448, 'grad_norm': 0.2293507605791092, 'learning_rate': 5.272727272727272e-05, 'epoch': 7.42}\n",
      "{'loss': 1.2286, 'grad_norm': 0.23261724412441254, 'learning_rate': 5.2272727272727274e-05, 'epoch': 7.44}\n",
      "{'loss': 1.2991, 'grad_norm': 0.2500031888484955, 'learning_rate': 5.181818181818182e-05, 'epoch': 7.47}\n",
      "{'loss': 1.3334, 'grad_norm': 0.278001993894577, 'learning_rate': 5.136363636363637e-05, 'epoch': 7.49}\n",
      "{'loss': 1.1336, 'grad_norm': 0.20719940960407257, 'learning_rate': 5.090909090909091e-05, 'epoch': 7.51}\n",
      "{'loss': 1.0647, 'grad_norm': 0.2080913633108139, 'learning_rate': 5.045454545454545e-05, 'epoch': 7.53}\n",
      "{'loss': 1.1413, 'grad_norm': 0.20045596361160278, 'learning_rate': 5e-05, 'epoch': 7.56}\n",
      "{'loss': 1.0815, 'grad_norm': 0.20217719674110413, 'learning_rate': 4.9545454545454553e-05, 'epoch': 7.58}\n",
      "{'loss': 1.137, 'grad_norm': 0.21525301039218903, 'learning_rate': 4.909090909090909e-05, 'epoch': 7.6}\n",
      "{'loss': 1.1938, 'grad_norm': 0.21773649752140045, 'learning_rate': 4.863636363636364e-05, 'epoch': 7.62}\n",
      "{'loss': 1.1219, 'grad_norm': 0.22077704966068268, 'learning_rate': 4.8181818181818186e-05, 'epoch': 7.64}\n",
      "{'loss': 1.1848, 'grad_norm': 0.21903792023658752, 'learning_rate': 4.772727272727273e-05, 'epoch': 7.67}\n",
      "{'loss': 1.1121, 'grad_norm': 0.2353769689798355, 'learning_rate': 4.7272727272727275e-05, 'epoch': 7.69}\n",
      "{'loss': 1.3464, 'grad_norm': 0.26858699321746826, 'learning_rate': 4.681818181818182e-05, 'epoch': 7.71}\n",
      "{'loss': 1.3285, 'grad_norm': 0.2573915421962738, 'learning_rate': 4.636363636363636e-05, 'epoch': 7.73}\n",
      "{'loss': 1.0564, 'grad_norm': 0.19848214089870453, 'learning_rate': 4.5909090909090914e-05, 'epoch': 7.76}\n",
      "{'loss': 1.0592, 'grad_norm': 0.19018672406673431, 'learning_rate': 4.545454545454546e-05, 'epoch': 7.78}\n",
      "{'loss': 1.0267, 'grad_norm': 0.1953967809677124, 'learning_rate': 4.5e-05, 'epoch': 7.8}\n",
      "{'loss': 1.0737, 'grad_norm': 0.20050029456615448, 'learning_rate': 4.454545454545455e-05, 'epoch': 7.82}\n",
      "{'loss': 1.0515, 'grad_norm': 0.2326766848564148, 'learning_rate': 4.409090909090909e-05, 'epoch': 7.84}\n",
      "{'loss': 1.0706, 'grad_norm': 0.2107003629207611, 'learning_rate': 4.3636363636363636e-05, 'epoch': 7.87}\n",
      "{'loss': 1.0774, 'grad_norm': 0.2570584714412689, 'learning_rate': 4.318181818181819e-05, 'epoch': 7.89}\n",
      "{'loss': 1.2612, 'grad_norm': 0.2464493066072464, 'learning_rate': 4.2727272727272724e-05, 'epoch': 7.91}\n",
      "{'loss': 1.3249, 'grad_norm': 0.2700559198856354, 'learning_rate': 4.2272727272727275e-05, 'epoch': 7.93}\n",
      "{'loss': 1.3939, 'grad_norm': 0.2842877209186554, 'learning_rate': 4.181818181818182e-05, 'epoch': 7.96}\n",
      "{'loss': 1.2573, 'grad_norm': 0.29011163115501404, 'learning_rate': 4.1363636363636364e-05, 'epoch': 7.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1497, 'grad_norm': 0.21001681685447693, 'learning_rate': 4.0909090909090915e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec168ab110f4f5b862a2fa52e9493af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.203382134437561, 'eval_runtime': 1.1059, 'eval_samples_per_second': 9.042, 'eval_steps_per_second': 9.042, 'epoch': 8.0}\n",
      "{'loss': 1.0979, 'grad_norm': 0.21353238821029663, 'learning_rate': 4.045454545454546e-05, 'epoch': 8.02}\n",
      "{'loss': 1.0559, 'grad_norm': 0.2105957567691803, 'learning_rate': 4e-05, 'epoch': 8.04}\n",
      "{'loss': 1.0584, 'grad_norm': 0.19047656655311584, 'learning_rate': 3.954545454545455e-05, 'epoch': 8.07}\n",
      "{'loss': 1.0726, 'grad_norm': 0.20908606052398682, 'learning_rate': 3.909090909090909e-05, 'epoch': 8.09}\n",
      "{'loss': 1.0692, 'grad_norm': 0.21913571655750275, 'learning_rate': 3.8636363636363636e-05, 'epoch': 8.11}\n",
      "{'loss': 1.1247, 'grad_norm': 0.19585619866847992, 'learning_rate': 3.818181818181819e-05, 'epoch': 8.13}\n",
      "{'loss': 1.0766, 'grad_norm': 0.2042999416589737, 'learning_rate': 3.7727272727272725e-05, 'epoch': 8.16}\n",
      "{'loss': 1.1035, 'grad_norm': 0.22026589512825012, 'learning_rate': 3.7272727272727276e-05, 'epoch': 8.18}\n",
      "{'loss': 1.1725, 'grad_norm': 0.24723248183727264, 'learning_rate': 3.681818181818182e-05, 'epoch': 8.2}\n",
      "{'loss': 1.2196, 'grad_norm': 0.247920960187912, 'learning_rate': 3.6363636363636364e-05, 'epoch': 8.22}\n",
      "{'loss': 1.3288, 'grad_norm': 0.2751878499984741, 'learning_rate': 3.590909090909091e-05, 'epoch': 8.24}\n",
      "{'loss': 1.0476, 'grad_norm': 0.1954895406961441, 'learning_rate': 3.545454545454546e-05, 'epoch': 8.27}\n",
      "{'loss': 1.0676, 'grad_norm': 0.21640343964099884, 'learning_rate': 3.5e-05, 'epoch': 8.29}\n",
      "{'loss': 1.0636, 'grad_norm': 0.19821356236934662, 'learning_rate': 3.454545454545455e-05, 'epoch': 8.31}\n",
      "{'loss': 1.1288, 'grad_norm': 0.22316192090511322, 'learning_rate': 3.409090909090909e-05, 'epoch': 8.33}\n",
      "{'loss': 1.1134, 'grad_norm': 0.21401503682136536, 'learning_rate': 3.3636363636363636e-05, 'epoch': 8.36}\n",
      "{'loss': 1.0654, 'grad_norm': 0.19742770493030548, 'learning_rate': 3.318181818181819e-05, 'epoch': 8.38}\n",
      "{'loss': 1.1007, 'grad_norm': 0.2486993372440338, 'learning_rate': 3.272727272727273e-05, 'epoch': 8.4}\n",
      "{'loss': 1.0928, 'grad_norm': 0.2198018878698349, 'learning_rate': 3.2272727272727276e-05, 'epoch': 8.42}\n",
      "{'loss': 1.0977, 'grad_norm': 0.21663735806941986, 'learning_rate': 3.181818181818182e-05, 'epoch': 8.44}\n",
      "{'loss': 1.185, 'grad_norm': 0.278635174036026, 'learning_rate': 3.1363636363636365e-05, 'epoch': 8.47}\n",
      "{'loss': 1.3258, 'grad_norm': 0.2884465754032135, 'learning_rate': 3.090909090909091e-05, 'epoch': 8.49}\n",
      "{'loss': 1.1187, 'grad_norm': 0.20153196156024933, 'learning_rate': 3.0454545454545456e-05, 'epoch': 8.51}\n",
      "{'loss': 1.1092, 'grad_norm': 0.21578650176525116, 'learning_rate': 3e-05, 'epoch': 8.53}\n",
      "{'loss': 1.032, 'grad_norm': 0.2091476321220398, 'learning_rate': 2.954545454545455e-05, 'epoch': 8.56}\n",
      "{'loss': 1.0134, 'grad_norm': 0.2074497640132904, 'learning_rate': 2.909090909090909e-05, 'epoch': 8.58}\n",
      "{'loss': 1.0202, 'grad_norm': 0.19530898332595825, 'learning_rate': 2.863636363636364e-05, 'epoch': 8.6}\n",
      "{'loss': 1.1347, 'grad_norm': 0.20989899337291718, 'learning_rate': 2.818181818181818e-05, 'epoch': 8.62}\n",
      "{'loss': 1.2064, 'grad_norm': 0.2218485176563263, 'learning_rate': 2.772727272727273e-05, 'epoch': 8.64}\n",
      "{'loss': 1.1416, 'grad_norm': 0.23221135139465332, 'learning_rate': 2.7272727272727273e-05, 'epoch': 8.67}\n",
      "{'loss': 1.2456, 'grad_norm': 0.25044623017311096, 'learning_rate': 2.681818181818182e-05, 'epoch': 8.69}\n",
      "{'loss': 1.2907, 'grad_norm': 0.27184993028640747, 'learning_rate': 2.636363636363636e-05, 'epoch': 8.71}\n",
      "{'loss': 1.1867, 'grad_norm': 0.27820661664009094, 'learning_rate': 2.590909090909091e-05, 'epoch': 8.73}\n",
      "{'loss': 1.0619, 'grad_norm': 0.20422229170799255, 'learning_rate': 2.5454545454545454e-05, 'epoch': 8.76}\n",
      "{'loss': 0.975, 'grad_norm': 0.19019752740859985, 'learning_rate': 2.5e-05, 'epoch': 8.78}\n",
      "{'loss': 1.0256, 'grad_norm': 0.19087541103363037, 'learning_rate': 2.4545454545454545e-05, 'epoch': 8.8}\n",
      "{'loss': 1.0006, 'grad_norm': 0.21222659945487976, 'learning_rate': 2.4090909090909093e-05, 'epoch': 8.82}\n",
      "{'loss': 1.087, 'grad_norm': 0.21950308978557587, 'learning_rate': 2.3636363636363637e-05, 'epoch': 8.84}\n",
      "{'loss': 1.0401, 'grad_norm': 0.22462135553359985, 'learning_rate': 2.318181818181818e-05, 'epoch': 8.87}\n",
      "{'loss': 1.2614, 'grad_norm': 0.25302645564079285, 'learning_rate': 2.272727272727273e-05, 'epoch': 8.89}\n",
      "{'loss': 1.2092, 'grad_norm': 0.24765025079250336, 'learning_rate': 2.2272727272727274e-05, 'epoch': 8.91}\n",
      "{'loss': 1.2952, 'grad_norm': 0.29119202494621277, 'learning_rate': 2.1818181818181818e-05, 'epoch': 8.93}\n",
      "{'loss': 1.2973, 'grad_norm': 0.2557644248008728, 'learning_rate': 2.1363636363636362e-05, 'epoch': 8.96}\n",
      "{'loss': 1.2422, 'grad_norm': 0.2846410870552063, 'learning_rate': 2.090909090909091e-05, 'epoch': 8.98}\n",
      "{'loss': 1.0429, 'grad_norm': 0.2082844376564026, 'learning_rate': 2.0454545454545457e-05, 'epoch': 9.0}\n",
      "{'loss': 1.0492, 'grad_norm': 0.2140810191631317, 'learning_rate': 2e-05, 'epoch': 9.02}\n",
      "{'loss': 1.0309, 'grad_norm': 0.199490487575531, 'learning_rate': 1.9545454545454546e-05, 'epoch': 9.04}\n",
      "{'loss': 1.0598, 'grad_norm': 0.21455320715904236, 'learning_rate': 1.9090909090909094e-05, 'epoch': 9.07}\n",
      "{'loss': 1.0441, 'grad_norm': 0.2037065178155899, 'learning_rate': 1.8636363636363638e-05, 'epoch': 9.09}\n",
      "{'loss': 1.0317, 'grad_norm': 0.2191494107246399, 'learning_rate': 1.8181818181818182e-05, 'epoch': 9.11}\n",
      "{'loss': 1.0881, 'grad_norm': 0.19623161852359772, 'learning_rate': 1.772727272727273e-05, 'epoch': 9.13}\n",
      "{'loss': 1.02, 'grad_norm': 0.20767337083816528, 'learning_rate': 1.7272727272727274e-05, 'epoch': 9.16}\n",
      "{'loss': 1.1621, 'grad_norm': 0.23214666545391083, 'learning_rate': 1.6818181818181818e-05, 'epoch': 9.18}\n",
      "{'loss': 1.1782, 'grad_norm': 0.2208484262228012, 'learning_rate': 1.6363636363636366e-05, 'epoch': 9.2}\n",
      "{'loss': 1.2178, 'grad_norm': 0.2602386772632599, 'learning_rate': 1.590909090909091e-05, 'epoch': 9.22}\n",
      "{'loss': 1.3408, 'grad_norm': 0.2737136781215668, 'learning_rate': 1.5454545454545454e-05, 'epoch': 9.24}\n",
      "{'loss': 1.0515, 'grad_norm': 0.21557055413722992, 'learning_rate': 1.5e-05, 'epoch': 9.27}\n",
      "{'loss': 0.9597, 'grad_norm': 0.2037634700536728, 'learning_rate': 1.4545454545454545e-05, 'epoch': 9.29}\n",
      "{'loss': 1.0219, 'grad_norm': 0.21167108416557312, 'learning_rate': 1.409090909090909e-05, 'epoch': 9.31}\n",
      "{'loss': 1.0395, 'grad_norm': 0.19852210581302643, 'learning_rate': 1.3636363636363637e-05, 'epoch': 9.33}\n",
      "{'loss': 1.0143, 'grad_norm': 0.2052718997001648, 'learning_rate': 1.318181818181818e-05, 'epoch': 9.36}\n",
      "{'loss': 1.0521, 'grad_norm': 0.2109803557395935, 'learning_rate': 1.2727272727272727e-05, 'epoch': 9.38}\n",
      "{'loss': 1.0065, 'grad_norm': 0.2200188785791397, 'learning_rate': 1.2272727272727273e-05, 'epoch': 9.4}\n",
      "{'loss': 1.0254, 'grad_norm': 0.24918591976165771, 'learning_rate': 1.1818181818181819e-05, 'epoch': 9.42}\n",
      "{'loss': 1.2043, 'grad_norm': 0.25099414587020874, 'learning_rate': 1.1363636363636365e-05, 'epoch': 9.44}\n",
      "{'loss': 1.3015, 'grad_norm': 0.2737829089164734, 'learning_rate': 1.0909090909090909e-05, 'epoch': 9.47}\n",
      "{'loss': 1.2229, 'grad_norm': 0.2921867072582245, 'learning_rate': 1.0454545454545455e-05, 'epoch': 9.49}\n",
      "{'loss': 1.0949, 'grad_norm': 0.21112695336341858, 'learning_rate': 1e-05, 'epoch': 9.51}\n",
      "{'loss': 1.0066, 'grad_norm': 0.20069153606891632, 'learning_rate': 9.545454545454547e-06, 'epoch': 9.53}\n",
      "{'loss': 1.0287, 'grad_norm': 0.20904387533664703, 'learning_rate': 9.090909090909091e-06, 'epoch': 9.56}\n",
      "{'loss': 1.0656, 'grad_norm': 0.20509089529514313, 'learning_rate': 8.636363636363637e-06, 'epoch': 9.58}\n",
      "{'loss': 1.1065, 'grad_norm': 0.2387126088142395, 'learning_rate': 8.181818181818183e-06, 'epoch': 9.6}\n",
      "{'loss': 1.0808, 'grad_norm': 0.22392171621322632, 'learning_rate': 7.727272727272727e-06, 'epoch': 9.62}\n",
      "{'loss': 1.1134, 'grad_norm': 0.2402547001838684, 'learning_rate': 7.272727272727272e-06, 'epoch': 9.64}\n",
      "{'loss': 1.0349, 'grad_norm': 0.23543953895568848, 'learning_rate': 6.818181818181818e-06, 'epoch': 9.67}\n",
      "{'loss': 1.2565, 'grad_norm': 0.2720147371292114, 'learning_rate': 6.363636363636363e-06, 'epoch': 9.69}\n",
      "{'loss': 1.2231, 'grad_norm': 0.2829086482524872, 'learning_rate': 5.909090909090909e-06, 'epoch': 9.71}\n",
      "{'loss': 1.2548, 'grad_norm': 0.2883443534374237, 'learning_rate': 5.4545454545454545e-06, 'epoch': 9.73}\n",
      "{'loss': 1.0116, 'grad_norm': 0.2034130096435547, 'learning_rate': 5e-06, 'epoch': 9.76}\n",
      "{'loss': 1.0933, 'grad_norm': 0.1970238834619522, 'learning_rate': 4.5454545454545455e-06, 'epoch': 9.78}\n",
      "{'loss': 0.9846, 'grad_norm': 0.19824561476707458, 'learning_rate': 4.0909090909090915e-06, 'epoch': 9.8}\n",
      "{'loss': 1.0372, 'grad_norm': 0.1945873200893402, 'learning_rate': 3.636363636363636e-06, 'epoch': 9.82}\n",
      "{'loss': 0.9963, 'grad_norm': 0.1980780065059662, 'learning_rate': 3.1818181818181817e-06, 'epoch': 9.84}\n",
      "{'loss': 1.0567, 'grad_norm': 0.22158050537109375, 'learning_rate': 2.7272727272727272e-06, 'epoch': 9.87}\n",
      "{'loss': 1.0473, 'grad_norm': 0.21991589665412903, 'learning_rate': 2.2727272727272728e-06, 'epoch': 9.89}\n",
      "{'loss': 1.1298, 'grad_norm': 0.23869571089744568, 'learning_rate': 1.818181818181818e-06, 'epoch': 9.91}\n",
      "{'loss': 1.1887, 'grad_norm': 0.24851641058921814, 'learning_rate': 1.3636363636363636e-06, 'epoch': 9.93}\n",
      "{'loss': 1.243, 'grad_norm': 0.24933968484401703, 'learning_rate': 9.09090909090909e-07, 'epoch': 9.96}\n",
      "{'loss': 1.2361, 'grad_norm': 0.3319171071052551, 'learning_rate': 4.545454545454545e-07, 'epoch': 9.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.034, 'grad_norm': 0.20743925869464874, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5781ac7fec61404290ff0869a9f2c6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1415091753005981, 'eval_runtime': 1.0759, 'eval_samples_per_second': 9.295, 'eval_steps_per_second': 9.295, 'epoch': 10.0}\n",
      "{'train_runtime': 228.1726, 'train_samples_per_second': 3.944, 'train_steps_per_second': 1.972, 'train_loss': 1.56362729522917, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=1.56362729522917, metrics={'train_runtime': 228.1726, 'train_samples_per_second': 3.944, 'train_steps_per_second': 1.972, 'total_flos': 2250468853800960.0, 'train_loss': 1.56362729522917, 'epoch': 10.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer of the question is: \n",
      "<Root>\n",
      "    <Actions>\n",
      "        <RequestAssistance>BringBowlOfSoup</Actions>\n",
      "        <NavigateTo>BeachChairAndUmbrella</Actions>\n",
      "        <Pick>Bowl</Actions>\n",
      "        <Place>BowlOnTable</Actions>\n",
      "    </Actions>\n",
      "</Root>\n",
      "Wait(10)\n",
      "<Actions>\n",
      "    <ExecuteCommand>move forward 5</Actions>\n",
      "    <ReleaseBowlOnTable</Actions>\n",
      "</Root>\n",
      "<Wait(5)>\n",
      "<Actions>\n",
      "    <Communicate>send message \"Thank you for bringing me soup!\"</Actions>\n",
      "</Root>\n",
      "<Wait(1)>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([\n",
    "    text\n",
    "], return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 2020, use_cache = True)\n",
    "\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer=answer[0].split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].split(EOS_TOKEN)[0]\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
