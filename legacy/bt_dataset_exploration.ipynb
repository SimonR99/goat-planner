{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You will be provided a summary of a task perfo...</td>\n",
       "      <td>The behavior tree orchestrates the navigation ...</td>\n",
       "      <td>&lt;!--\\n  This Behavior Tree replans the global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You will be provided a summary of a task perfo...</td>\n",
       "      <td>The behavior tree is designed to control a rob...</td>\n",
       "      <td>&lt;!--\\n  This Behavior Tree replans the global ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You will be provided a summary of a task perfo...</td>\n",
       "      <td>The behavior tree is a simple sequential task ...</td>\n",
       "      <td>&lt;root main_tree_to_execute = \"MainTree\" &gt;\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You will be provided a summary of a task perfo...</td>\n",
       "      <td>The behavior tree represents a robot's task. I...</td>\n",
       "      <td>&lt;root main_tree_to_execute = \"MainTree\" &gt;\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You will be provided a summary of a task perfo...</td>\n",
       "      <td>The behavior tree represents a robot's navigat...</td>\n",
       "      <td>&lt;!--\\n  This Behavior Tree first computes a pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  You will be provided a summary of a task perfo...   \n",
       "1  You will be provided a summary of a task perfo...   \n",
       "2  You will be provided a summary of a task perfo...   \n",
       "3  You will be provided a summary of a task perfo...   \n",
       "4  You will be provided a summary of a task perfo...   \n",
       "\n",
       "                                               input  \\\n",
       "0  The behavior tree orchestrates the navigation ...   \n",
       "1  The behavior tree is designed to control a rob...   \n",
       "2  The behavior tree is a simple sequential task ...   \n",
       "3  The behavior tree represents a robot's task. I...   \n",
       "4  The behavior tree represents a robot's navigat...   \n",
       "\n",
       "                                              output  \n",
       "0  <!--\\n  This Behavior Tree replans the global ...  \n",
       "1  <!--\\n  This Behavior Tree replans the global ...  \n",
       "2  <root main_tree_to_execute = \"MainTree\" >\\n   ...  \n",
       "3  <root main_tree_to_execute = \"MainTree\" >\\n   ...  \n",
       "4  <!--\\n  This Behavior Tree first computes a pa...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"./bt_dataset.json\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 594 entries, 0 to 593\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  594 non-null    object\n",
      " 1   input        594 non-null    object\n",
      " 2   output       594 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 14.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\"\n",
    "\n",
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer= AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9140b135c24f69805ce6ec021f6b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_instruction = \"You will be provided a summary of a task performed by a behavior tree, and your objective is to express this behavior tree in XML format.\"\n",
    "data_prompt = base_instruction + \"\"\"\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Output:\n",
    "{}\"\"\"\n",
    "\n",
    "training_data = Dataset.from_pandas(data)\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompt(examples):\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for input_, output in zip(inputs, outputs):\n",
    "        text = data_prompt.format(input_, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "training_data = Dataset.from_pandas(data)\n",
    "training_data = training_data.map(formatting_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38f2f31a5244774a1938fb6cfff169b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You will be provided a summary of a task performed by a behavior tree, and your objective is to express this behavior tree in XML format.<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "The behavior tree orchestrates the navigation of a robot by periodically replanning its global path at a frequency of 1 Hz. It utilizes a pipeline sequence, where it first computes a path to a specified goal using a \"GridBased\" planner and then follows this computed path using a designated controller. This approach ensures that the robot continuously updates its path to adapt to dynamic environments or changing conditions, enabling it to navigate effectively towards its goal while avoiding obstacles or other potential disruptions.<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "<!--\n",
      "  This Behavior Tree replans the global path periodically at 1 Hz.\n",
      "-->\n",
      "\n",
      "<root main_tree_to_execute=\"MainTree\">\n",
      "  <BehaviorTree ID=\"MainTree\">\n",
      "    <PipelineSequence name=\"NavigateWithReplanning\">\n",
      "      <RateController hz=\"1.0\">\n",
      "        <ComputePathToPose goal=\"{goal}\" path=\"{path}\" planner_id=\"GridBased\"/>\n",
      "      </RateController>\n",
      "      <FollowPath path=\"{path}\"  controller_id=\"FollowPath\"/>\n",
      "    </PipelineSequence>\n",
      "  </BehaviorTree>\n",
      "</root>\n",
      "\n",
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "data_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = \"<|eot_id|>\"\n",
    "\n",
    "def formatting_prompt(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction,input_, output in zip(instructions, inputs, outputs):\n",
    "        text = data_prompt.format(instruction,input_, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "\n",
    "# Create the dataset and apply the mapping\n",
    "training_data = Dataset.from_pandas(data)\n",
    "training_data = training_data.map(formatting_prompt, batched=True)\n",
    "\n",
    "# Display a sample for verification\n",
    "print(training_data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|eot_id|>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\nYou will be provided a summary of a task performed by a behavior tree, and your objective is to express this behavior tree in XML format.<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\nThe behavior tree orchestrates the navigation of a robot by periodically replanning its global path at a frequency of 1 Hz. It utilizes a pipeline sequence, where it first computes a path to a specified goal using a \"GridBased\" planner and then follows this computed path using a designated controller. This approach ensures that the robot continuously updates its path to adapt to dynamic environments or changing conditions, enabling it to navigate effectively towards its goal while avoiding obstacles or other potential disruptions.<|eot_id|>\\n<|start_header_id|>assistant<|end_header_id|>\\n<!--\\n  This Behavior Tree replans the global path periodically at 1 Hz.\\n-->\\n\\n<root main_tree_to_execute=\"MainTree\">\\n  <BehaviorTree ID=\"MainTree\">\\n    <PipelineSequence name=\"NavigateWithReplanning\">\\n      <RateController hz=\"1.0\">\\n        <ComputePathToPose goal=\"{goal}\" path=\"{path}\" planner_id=\"GridBased\"/>\\n      </RateController>\\n      <FollowPath path=\"{path}\"  controller_id=\"FollowPath\"/>\\n    </PipelineSequence>\\n  </BehaviorTree>\\n</root>\\n\\n<|eot_id|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/simon/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/simon/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c5b84f3a8042b3b71b6ca3d686467a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/534 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0e5301a9774c8b96ad0beb56ed3aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "\n",
    "\n",
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules\n",
    ")\n",
    "\n",
    "new_model = \"llama-3.2-3b-it-Ecommerce-ChatBot\"\n",
    "\n",
    "#Hyperparamter\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "# Create train/test split\n",
    "full_dataset = training_data.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=full_dataset[\"train\"],\n",
    "    eval_dataset=full_dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer of the question is: \n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Here is a sample XML representation of a behavior tree for the robot navigation task:\n",
      "```\n",
      "<behavior tree>\n",
      "  <goal>\n",
      "    <name>ReachGoal</name>\n",
      "    <description>Reach the goal</description>\n",
      "  </goal>\n",
      "  <plan>\n",
      "    <sequence>\n",
      "      <grid-based-planner>\n",
      "        <plan-name>PlanPath</plan-name>\n",
      "        <parameters>\n",
      "          <parameter>\n",
      "            <name>gridSize</name>\n",
      "            <type>integer</type>\n",
      "            <value>20</value>\n",
      "          </parameter>\n",
      "          <parameter>\n",
      "            <name>goalDistance</name>\n",
      "            <type>float</type>\n",
      "            <value>1</value>\n",
      "          </parameter>\n",
      "          <parameter>\n",
      "            <name>obstacleDistance</name>\n",
      "            <type>float</type>\n",
      "            <value>0.5</value>\n",
      "          </parameter>\n",
      "        </parameters>\n",
      "        <grid-based-planner>\n",
      "          <plan-name>ComputePath</plan-name>\n",
      "          <parameters>\n",
      "            <parameter>\n",
      "              <name>obstacles</name>\n",
      "              <type>array</type>\n",
      "              <value>\n",
      "                <element>obstacle</element>\n",
      "              </value>\n",
      "            </parameter>\n",
      "          </parameters>\n",
      "        </grid-based-planner>\n",
      "        <controller>\n",
      "          <name>UpdatePath</name>\n",
      "          <parameters>\n",
      "            <parameter>\n",
      "              <name>path</name>\n",
      "              <type>array</type>\n",
      "              <value>\n",
      "                <element>path</element>\n",
      "              </value>\n",
      "            </parameter>\n",
      "          </parameters>\n",
      "        </controller>\n",
      "      </sequence>\n",
      "    </plan>\n",
      "  </plan>\n",
      "  <controller>\n",
      "    <name>UpdatePath</name>\n",
      "    <parameters>\n",
      "      <parameter>\n",
      "        <name>path</name>\n",
      "        <type>array</type>\n",
      "        <value>\n",
      "          <element>path</element>\n",
      "        </value>\n",
      "      </parameter>\n",
      "    </parameters>\n",
      "  </controller>\n",
      "  <plan>\n",
      "    <name>PlanPath</name>\n",
      "    <parameters>\n",
      "      <parameter>\n",
      "        <name>path</name>\n",
      "        <type>array</type>\n",
      "        <value>\n",
      "          <element>path</element>\n",
      "        </value>\n",
      "      </parameter>\n",
      "    </parameters>\n",
      "  </plan>\n",
      "</behavior tree>\n",
      "```\n",
      "Note that this is a simplified representation and may need to be modified to fit the specific requirements of your robot and environment. Additionally, the XML structure may need to be adjusted to accommodate the actual structure of the planner and controller nodes.\n",
      "\n",
      "Here's a brief explanation of the XML structure:\n",
      "\n",
      "* `<behavior tree>`: The root element of the XML representation, which contains the entire behavior tree.\n",
      "* `<goal>`: Contains the goal node, which specifies the name and description of the goal.\n",
      "* `<plan>`: Contains the plan node, which specifies the sequence of nodes that the robot will follow.\n",
      "* `<sequence>`: A sequence of nodes that the robot will follow.\n",
      "* `<grid-based-planner>`: A planner node that computes the path to the goal.\n",
      "* `<parameters>`: A set of parameters that are used by the planner.\n",
      "* `<controller>`: A controller node that updates the path.\n",
      "* `<parameters>`: A set of parameters that are used by the controller.\n",
      "\n",
      "The XML structure includes the following elements:\n",
      "\n",
      "* `grid-based-planner`: This node specifies the planner and its parameters.\n",
      "* `parameters`: This node specifies the parameters used by the planner.\n",
      "* `controller`: This node specifies the controller and its parameters.\n",
      "* `parameters`: This node specifies the parameters used by the controller.\n",
      "\n",
      "The XML structure assumes that the planner and controller nodes are part of a pipeline sequence, where the planner computes the path and the controller updates the path based on the computed path. The `grid-based-planner` node uses a grid-based planner to compute the path, while the `controller` node uses the computed path to update the path.\n"
     ]
    }
   ],
   "source": [
    "text=\"The behavior tree orchestrates the navigation of a robot by periodically replanning its global path at a frequency of 1 Hz. It utilizes a pipeline sequence, where it first computes a path to a specified goal using a \\\"GridBased\\\" planner and then follows this computed path using a designated controller. This approach ensures that the robot continuously updates its path to adapt to dynamic environments or changing conditions, enabling it to navigate effectively towards its goal while avoiding obstacles or other potential disruptions.\"\n",
    "\n",
    "inputs = tokenizer([\n",
    "    data_prompt.format(base_instruction, text, \"\")\n",
    "], return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 2020)\n",
    "\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer_short = answer[0].split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
    "print(\"Answer of the question is:\", answer_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimonroy99\u001b[0m (\u001b[33msimonroy99-cole-de-technologie-sup-rieure\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/simon/workspace/ETS/SYS819/proteus/training/wandb/run-20241124_213915-jpzl5q4b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/jpzl5q4b' target=\"_blank\">llama-3.2-3b-it-Ecommerce-ChatBot</a></strong> to <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface' target=\"_blank\">https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/jpzl5q4b' target=\"_blank\">https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/jpzl5q4b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf0e44f97a34285aa3f43564496a16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1013, 'grad_norm': 1.8830718994140625, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
      "{'loss': 2.421, 'grad_norm': 1.8772141933441162, 'learning_rate': 4e-05, 'epoch': 0.01}\n",
      "{'loss': 2.7165, 'grad_norm': 2.0224382877349854, 'learning_rate': 6e-05, 'epoch': 0.01}\n",
      "{'loss': 2.3947, 'grad_norm': 1.8407808542251587, 'learning_rate': 8e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1724, 'grad_norm': 1.8222862482070923, 'learning_rate': 0.0001, 'epoch': 0.02}\n",
      "{'loss': 2.1665, 'grad_norm': 1.8011784553527832, 'learning_rate': 0.00012, 'epoch': 0.02}\n",
      "{'loss': 2.0663, 'grad_norm': 1.4311195611953735, 'learning_rate': 0.00014, 'epoch': 0.03}\n",
      "{'loss': 1.9541, 'grad_norm': 1.2858277559280396, 'learning_rate': 0.00016, 'epoch': 0.03}\n",
      "{'loss': 2.2059, 'grad_norm': 1.5256670713424683, 'learning_rate': 0.00018, 'epoch': 0.03}\n",
      "{'loss': 1.9583, 'grad_norm': 1.4222426414489746, 'learning_rate': 0.0002, 'epoch': 0.04}\n",
      "{'loss': 1.6651, 'grad_norm': 1.292578935623169, 'learning_rate': 0.0001992217898832685, 'epoch': 0.04}\n",
      "{'loss': 1.5893, 'grad_norm': 1.354783296585083, 'learning_rate': 0.00019844357976653697, 'epoch': 0.04}\n",
      "{'loss': 1.8087, 'grad_norm': 1.5311733484268188, 'learning_rate': 0.00019766536964980547, 'epoch': 0.05}\n",
      "{'loss': 1.6172, 'grad_norm': 1.4202812910079956, 'learning_rate': 0.00019688715953307395, 'epoch': 0.05}\n",
      "{'loss': 1.6198, 'grad_norm': 1.5201287269592285, 'learning_rate': 0.0001961089494163424, 'epoch': 0.06}\n",
      "{'loss': 1.5195, 'grad_norm': 1.4324134588241577, 'learning_rate': 0.0001953307392996109, 'epoch': 0.06}\n",
      "{'loss': 1.2378, 'grad_norm': 1.1877715587615967, 'learning_rate': 0.0001945525291828794, 'epoch': 0.06}\n",
      "{'loss': 1.3717, 'grad_norm': 1.3104814291000366, 'learning_rate': 0.00019377431906614787, 'epoch': 0.07}\n",
      "{'loss': 1.399, 'grad_norm': 2.035553455352783, 'learning_rate': 0.00019299610894941635, 'epoch': 0.07}\n",
      "{'loss': 1.3885, 'grad_norm': 1.4009394645690918, 'learning_rate': 0.00019221789883268483, 'epoch': 0.07}\n",
      "{'loss': 1.5144, 'grad_norm': 1.561927318572998, 'learning_rate': 0.00019143968871595333, 'epoch': 0.08}\n",
      "{'loss': 1.1364, 'grad_norm': 1.2981044054031372, 'learning_rate': 0.00019066147859922181, 'epoch': 0.08}\n",
      "{'loss': 1.2492, 'grad_norm': 1.4892162084579468, 'learning_rate': 0.00018988326848249027, 'epoch': 0.09}\n",
      "{'loss': 1.135, 'grad_norm': 1.4782090187072754, 'learning_rate': 0.00018910505836575875, 'epoch': 0.09}\n",
      "{'loss': 1.2709, 'grad_norm': 1.4371438026428223, 'learning_rate': 0.00018832684824902725, 'epoch': 0.09}\n",
      "{'loss': 1.2052, 'grad_norm': 1.6871505975723267, 'learning_rate': 0.00018754863813229573, 'epoch': 0.1}\n",
      "{'loss': 1.0693, 'grad_norm': 2.0066025257110596, 'learning_rate': 0.0001867704280155642, 'epoch': 0.1}\n",
      "{'loss': 1.1192, 'grad_norm': 1.4875199794769287, 'learning_rate': 0.0001859922178988327, 'epoch': 0.1}\n",
      "{'loss': 1.1031, 'grad_norm': 1.4574123620986938, 'learning_rate': 0.0001852140077821012, 'epoch': 0.11}\n",
      "{'loss': 0.9701, 'grad_norm': 1.5550034046173096, 'learning_rate': 0.00018443579766536967, 'epoch': 0.11}\n",
      "{'loss': 0.9948, 'grad_norm': 1.59283447265625, 'learning_rate': 0.00018365758754863813, 'epoch': 0.12}\n",
      "{'loss': 1.2317, 'grad_norm': 1.727707862854004, 'learning_rate': 0.0001828793774319066, 'epoch': 0.12}\n",
      "{'loss': 1.5649, 'grad_norm': 1.807557225227356, 'learning_rate': 0.0001821011673151751, 'epoch': 0.12}\n",
      "{'loss': 1.3156, 'grad_norm': 1.7319552898406982, 'learning_rate': 0.0001813229571984436, 'epoch': 0.13}\n",
      "{'loss': 1.4701, 'grad_norm': 1.9064887762069702, 'learning_rate': 0.00018054474708171207, 'epoch': 0.13}\n",
      "{'loss': 1.2108, 'grad_norm': 1.6200098991394043, 'learning_rate': 0.00017976653696498055, 'epoch': 0.13}\n",
      "{'loss': 0.9325, 'grad_norm': 1.426297664642334, 'learning_rate': 0.00017898832684824906, 'epoch': 0.14}\n",
      "{'loss': 1.0494, 'grad_norm': 1.4941024780273438, 'learning_rate': 0.00017821011673151754, 'epoch': 0.14}\n",
      "{'loss': 1.1228, 'grad_norm': 1.5289117097854614, 'learning_rate': 0.000177431906614786, 'epoch': 0.15}\n",
      "{'loss': 1.2356, 'grad_norm': 1.490403175354004, 'learning_rate': 0.00017665369649805447, 'epoch': 0.15}\n",
      "{'loss': 1.1679, 'grad_norm': 1.661973476409912, 'learning_rate': 0.00017587548638132297, 'epoch': 0.15}\n",
      "{'loss': 1.2682, 'grad_norm': 1.7366302013397217, 'learning_rate': 0.00017509727626459145, 'epoch': 0.16}\n",
      "{'loss': 1.0017, 'grad_norm': 1.4348667860031128, 'learning_rate': 0.00017431906614785993, 'epoch': 0.16}\n",
      "{'loss': 1.0387, 'grad_norm': 1.516218662261963, 'learning_rate': 0.0001735408560311284, 'epoch': 0.16}\n",
      "{'loss': 0.7725, 'grad_norm': 1.1489026546478271, 'learning_rate': 0.00017276264591439692, 'epoch': 0.17}\n",
      "{'loss': 1.4639, 'grad_norm': 2.287400007247925, 'learning_rate': 0.0001719844357976654, 'epoch': 0.17}\n",
      "{'loss': 0.842, 'grad_norm': 1.4787498712539673, 'learning_rate': 0.00017120622568093385, 'epoch': 0.18}\n",
      "{'loss': 1.1232, 'grad_norm': 1.9782524108886719, 'learning_rate': 0.00017042801556420233, 'epoch': 0.18}\n",
      "{'loss': 0.9612, 'grad_norm': 1.8879005908966064, 'learning_rate': 0.00016964980544747083, 'epoch': 0.18}\n",
      "{'loss': 0.8018, 'grad_norm': 1.5435292720794678, 'learning_rate': 0.0001688715953307393, 'epoch': 0.19}\n",
      "{'loss': 1.6385, 'grad_norm': 1.798567533493042, 'learning_rate': 0.0001680933852140078, 'epoch': 0.19}\n",
      "{'loss': 1.2913, 'grad_norm': 1.3344439268112183, 'learning_rate': 0.00016731517509727627, 'epoch': 0.19}\n",
      "{'loss': 1.3602, 'grad_norm': 1.7748901844024658, 'learning_rate': 0.00016653696498054475, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9368, 'grad_norm': 1.131678581237793, 'learning_rate': 0.00016575875486381326, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe851acc702547c29b13c0bdf7c99336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0513944625854492, 'eval_runtime': 7.1822, 'eval_samples_per_second': 8.354, 'eval_steps_per_second': 8.354, 'epoch': 0.2}\n",
      "{'loss': 1.1019, 'grad_norm': 1.245175838470459, 'learning_rate': 0.0001649805447470817, 'epoch': 0.21}\n",
      "{'loss': 1.6829, 'grad_norm': 1.2905633449554443, 'learning_rate': 0.0001642023346303502, 'epoch': 0.21}\n",
      "{'loss': 0.8785, 'grad_norm': 1.0657894611358643, 'learning_rate': 0.0001634241245136187, 'epoch': 0.21}\n",
      "{'loss': 1.6903, 'grad_norm': 1.3576346635818481, 'learning_rate': 0.00016264591439688717, 'epoch': 0.22}\n",
      "{'loss': 1.1169, 'grad_norm': 1.0778228044509888, 'learning_rate': 0.00016186770428015565, 'epoch': 0.22}\n",
      "{'loss': 1.1219, 'grad_norm': 1.0789772272109985, 'learning_rate': 0.00016108949416342413, 'epoch': 0.22}\n",
      "{'loss': 1.3648, 'grad_norm': 1.075291395187378, 'learning_rate': 0.0001603112840466926, 'epoch': 0.23}\n",
      "{'loss': 1.1717, 'grad_norm': 1.0265227556228638, 'learning_rate': 0.00015953307392996112, 'epoch': 0.23}\n",
      "{'loss': 1.1388, 'grad_norm': 1.1133872270584106, 'learning_rate': 0.00015875486381322957, 'epoch': 0.24}\n",
      "{'loss': 1.0544, 'grad_norm': 0.9788525104522705, 'learning_rate': 0.00015797665369649805, 'epoch': 0.24}\n",
      "{'loss': 0.9316, 'grad_norm': 1.0322747230529785, 'learning_rate': 0.00015719844357976655, 'epoch': 0.24}\n",
      "{'loss': 1.2338, 'grad_norm': 1.2357667684555054, 'learning_rate': 0.00015642023346303503, 'epoch': 0.25}\n",
      "{'loss': 1.0065, 'grad_norm': 0.9970971345901489, 'learning_rate': 0.0001556420233463035, 'epoch': 0.25}\n",
      "{'loss': 1.2573, 'grad_norm': 1.0660779476165771, 'learning_rate': 0.000154863813229572, 'epoch': 0.25}\n",
      "{'loss': 0.8735, 'grad_norm': 0.9869838356971741, 'learning_rate': 0.00015408560311284047, 'epoch': 0.26}\n",
      "{'loss': 1.3821, 'grad_norm': 1.3274270296096802, 'learning_rate': 0.00015330739299610898, 'epoch': 0.26}\n",
      "{'loss': 0.6885, 'grad_norm': 0.9312482476234436, 'learning_rate': 0.00015252918287937743, 'epoch': 0.27}\n",
      "{'loss': 1.1617, 'grad_norm': 1.1339191198349, 'learning_rate': 0.0001517509727626459, 'epoch': 0.27}\n",
      "{'loss': 0.7822, 'grad_norm': 0.957426905632019, 'learning_rate': 0.0001509727626459144, 'epoch': 0.27}\n",
      "{'loss': 0.9281, 'grad_norm': 1.1994221210479736, 'learning_rate': 0.0001501945525291829, 'epoch': 0.28}\n",
      "{'loss': 0.6832, 'grad_norm': 1.1284546852111816, 'learning_rate': 0.00014941634241245137, 'epoch': 0.28}\n",
      "{'loss': 1.3132, 'grad_norm': 1.492560863494873, 'learning_rate': 0.00014863813229571985, 'epoch': 0.28}\n",
      "{'loss': 0.9504, 'grad_norm': 1.3957107067108154, 'learning_rate': 0.00014785992217898833, 'epoch': 0.29}\n",
      "{'loss': 1.1677, 'grad_norm': 1.386248230934143, 'learning_rate': 0.00014708171206225684, 'epoch': 0.29}\n",
      "{'loss': 0.7927, 'grad_norm': 1.4583884477615356, 'learning_rate': 0.0001463035019455253, 'epoch': 0.3}\n",
      "{'loss': 0.9145, 'grad_norm': 1.2295924425125122, 'learning_rate': 0.00014552529182879377, 'epoch': 0.3}\n",
      "{'loss': 0.963, 'grad_norm': 1.4502686262130737, 'learning_rate': 0.00014474708171206225, 'epoch': 0.3}\n",
      "{'loss': 0.667, 'grad_norm': 1.05968177318573, 'learning_rate': 0.00014396887159533075, 'epoch': 0.31}\n",
      "{'loss': 1.1806, 'grad_norm': 1.4052226543426514, 'learning_rate': 0.00014319066147859923, 'epoch': 0.31}\n",
      "{'loss': 0.8525, 'grad_norm': 1.3152998685836792, 'learning_rate': 0.0001424124513618677, 'epoch': 0.31}\n",
      "{'loss': 0.9312, 'grad_norm': 1.3908675909042358, 'learning_rate': 0.0001416342412451362, 'epoch': 0.32}\n",
      "{'loss': 1.0401, 'grad_norm': 1.4442085027694702, 'learning_rate': 0.0001408560311284047, 'epoch': 0.32}\n",
      "{'loss': 0.7519, 'grad_norm': 1.2348241806030273, 'learning_rate': 0.00014007782101167315, 'epoch': 0.33}\n",
      "{'loss': 0.6507, 'grad_norm': 1.0607243776321411, 'learning_rate': 0.00013929961089494163, 'epoch': 0.33}\n",
      "{'loss': 0.7676, 'grad_norm': 1.211450457572937, 'learning_rate': 0.0001385214007782101, 'epoch': 0.33}\n",
      "{'loss': 0.8703, 'grad_norm': 1.5914971828460693, 'learning_rate': 0.00013774319066147862, 'epoch': 0.34}\n",
      "{'loss': 1.2577, 'grad_norm': 1.7918570041656494, 'learning_rate': 0.0001369649805447471, 'epoch': 0.34}\n",
      "{'loss': 0.7417, 'grad_norm': 1.3215070962905884, 'learning_rate': 0.00013618677042801557, 'epoch': 0.34}\n",
      "{'loss': 0.5602, 'grad_norm': 1.3912081718444824, 'learning_rate': 0.00013540856031128405, 'epoch': 0.35}\n",
      "{'loss': 0.837, 'grad_norm': 1.7148337364196777, 'learning_rate': 0.00013463035019455256, 'epoch': 0.35}\n",
      "{'loss': 1.1533, 'grad_norm': 1.850935935974121, 'learning_rate': 0.000133852140077821, 'epoch': 0.36}\n",
      "{'loss': 0.8473, 'grad_norm': 1.7714568376541138, 'learning_rate': 0.0001330739299610895, 'epoch': 0.36}\n",
      "{'loss': 1.0063, 'grad_norm': 2.0654120445251465, 'learning_rate': 0.00013229571984435797, 'epoch': 0.36}\n",
      "{'loss': 1.1011, 'grad_norm': 2.2496066093444824, 'learning_rate': 0.00013151750972762648, 'epoch': 0.37}\n",
      "{'loss': 0.9017, 'grad_norm': 2.3293240070343018, 'learning_rate': 0.00013073929961089496, 'epoch': 0.37}\n",
      "{'loss': 0.8389, 'grad_norm': 2.337012767791748, 'learning_rate': 0.00012996108949416343, 'epoch': 0.37}\n",
      "{'loss': 1.003, 'grad_norm': 1.416899561882019, 'learning_rate': 0.0001291828793774319, 'epoch': 0.38}\n",
      "{'loss': 0.989, 'grad_norm': 1.2603754997253418, 'learning_rate': 0.0001284046692607004, 'epoch': 0.38}\n",
      "{'loss': 1.1478, 'grad_norm': 1.5605440139770508, 'learning_rate': 0.00012762645914396887, 'epoch': 0.39}\n",
      "{'loss': 0.8542, 'grad_norm': 1.3792556524276733, 'learning_rate': 0.00012684824902723735, 'epoch': 0.39}\n",
      "{'loss': 1.1891, 'grad_norm': 1.6735930442810059, 'learning_rate': 0.00012607003891050583, 'epoch': 0.39}\n",
      "{'loss': 0.9167, 'grad_norm': 1.2750285863876343, 'learning_rate': 0.00012529182879377434, 'epoch': 0.4}\n",
      "{'loss': 1.2023, 'grad_norm': 1.7366876602172852, 'learning_rate': 0.00012451361867704282, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0815, 'grad_norm': 1.4700428247451782, 'learning_rate': 0.0001237354085603113, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66fc6529ed944f95ad7ded80195172e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8824385404586792, 'eval_runtime': 7.1601, 'eval_samples_per_second': 8.38, 'eval_steps_per_second': 8.38, 'epoch': 0.4}\n",
      "{'loss': 1.3075, 'grad_norm': 1.4731686115264893, 'learning_rate': 0.00012295719844357977, 'epoch': 0.41}\n",
      "{'loss': 1.109, 'grad_norm': 1.3077154159545898, 'learning_rate': 0.00012217898832684825, 'epoch': 0.41}\n",
      "{'loss': 0.892, 'grad_norm': 1.0182552337646484, 'learning_rate': 0.00012140077821011673, 'epoch': 0.42}\n",
      "{'loss': 1.2891, 'grad_norm': 1.2608592510223389, 'learning_rate': 0.00012062256809338521, 'epoch': 0.42}\n",
      "{'loss': 1.1296, 'grad_norm': 1.3740692138671875, 'learning_rate': 0.0001198443579766537, 'epoch': 0.42}\n",
      "{'loss': 0.8057, 'grad_norm': 1.1053519248962402, 'learning_rate': 0.00011906614785992218, 'epoch': 0.43}\n",
      "{'loss': 0.9645, 'grad_norm': 1.1471889019012451, 'learning_rate': 0.00011828793774319066, 'epoch': 0.43}\n",
      "{'loss': 1.2156, 'grad_norm': 1.1369529962539673, 'learning_rate': 0.00011750972762645916, 'epoch': 0.43}\n",
      "{'loss': 1.106, 'grad_norm': 1.0692317485809326, 'learning_rate': 0.00011673151750972763, 'epoch': 0.44}\n",
      "{'loss': 0.9519, 'grad_norm': 1.0242849588394165, 'learning_rate': 0.00011595330739299613, 'epoch': 0.44}\n",
      "{'loss': 1.472, 'grad_norm': 1.339809536933899, 'learning_rate': 0.00011517509727626459, 'epoch': 0.45}\n",
      "{'loss': 1.1086, 'grad_norm': 1.2673976421356201, 'learning_rate': 0.00011439688715953307, 'epoch': 0.45}\n",
      "{'loss': 1.0202, 'grad_norm': 1.287301778793335, 'learning_rate': 0.00011361867704280155, 'epoch': 0.45}\n",
      "{'loss': 0.7432, 'grad_norm': 1.2427482604980469, 'learning_rate': 0.00011284046692607004, 'epoch': 0.46}\n",
      "{'loss': 0.7266, 'grad_norm': 1.0656803846359253, 'learning_rate': 0.00011206225680933852, 'epoch': 0.46}\n",
      "{'loss': 0.7948, 'grad_norm': 1.2187448740005493, 'learning_rate': 0.00011128404669260702, 'epoch': 0.46}\n",
      "{'loss': 0.6619, 'grad_norm': 1.0612900257110596, 'learning_rate': 0.0001105058365758755, 'epoch': 0.47}\n",
      "{'loss': 1.007, 'grad_norm': 1.4478729963302612, 'learning_rate': 0.00010972762645914399, 'epoch': 0.47}\n",
      "{'loss': 0.9616, 'grad_norm': 1.3064332008361816, 'learning_rate': 0.00010894941634241245, 'epoch': 0.48}\n",
      "{'loss': 0.96, 'grad_norm': 1.392114520072937, 'learning_rate': 0.00010817120622568093, 'epoch': 0.48}\n",
      "{'loss': 0.8984, 'grad_norm': 1.1657865047454834, 'learning_rate': 0.00010739299610894941, 'epoch': 0.48}\n",
      "{'loss': 0.8562, 'grad_norm': 1.2824584245681763, 'learning_rate': 0.0001066147859922179, 'epoch': 0.49}\n",
      "{'loss': 0.779, 'grad_norm': 1.3896604776382446, 'learning_rate': 0.00010583657587548638, 'epoch': 0.49}\n",
      "{'loss': 0.7467, 'grad_norm': 1.2695788145065308, 'learning_rate': 0.00010505836575875488, 'epoch': 0.49}\n",
      "{'loss': 0.7342, 'grad_norm': 1.303218126296997, 'learning_rate': 0.00010428015564202336, 'epoch': 0.5}\n",
      "{'loss': 1.1527, 'grad_norm': 1.3927701711654663, 'learning_rate': 0.00010350194552529185, 'epoch': 0.5}\n",
      "{'loss': 0.7044, 'grad_norm': 1.0881984233856201, 'learning_rate': 0.0001027237354085603, 'epoch': 0.51}\n",
      "{'loss': 0.5513, 'grad_norm': 1.241666555404663, 'learning_rate': 0.0001019455252918288, 'epoch': 0.51}\n",
      "{'loss': 0.9843, 'grad_norm': 1.5364807844161987, 'learning_rate': 0.00010116731517509727, 'epoch': 0.51}\n",
      "{'loss': 1.1394, 'grad_norm': 1.6745325326919556, 'learning_rate': 0.00010038910505836577, 'epoch': 0.52}\n",
      "{'loss': 0.4355, 'grad_norm': 1.0027542114257812, 'learning_rate': 9.961089494163424e-05, 'epoch': 0.52}\n",
      "{'loss': 0.4842, 'grad_norm': 1.5111883878707886, 'learning_rate': 9.883268482490274e-05, 'epoch': 0.52}\n",
      "{'loss': 0.9309, 'grad_norm': 1.5975465774536133, 'learning_rate': 9.80544747081712e-05, 'epoch': 0.53}\n",
      "{'loss': 0.7889, 'grad_norm': 1.5370774269104004, 'learning_rate': 9.72762645914397e-05, 'epoch': 0.53}\n",
      "{'loss': 0.5465, 'grad_norm': 1.2883366346359253, 'learning_rate': 9.649805447470817e-05, 'epoch': 0.54}\n",
      "{'loss': 0.7741, 'grad_norm': 1.6367546319961548, 'learning_rate': 9.571984435797667e-05, 'epoch': 0.54}\n",
      "{'loss': 0.8211, 'grad_norm': 1.6366171836853027, 'learning_rate': 9.494163424124513e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6902, 'grad_norm': 1.5564019680023193, 'learning_rate': 9.416342412451363e-05, 'epoch': 0.55}\n",
      "{'loss': 0.6078, 'grad_norm': 1.7230569124221802, 'learning_rate': 9.33852140077821e-05, 'epoch': 0.55}\n",
      "{'loss': 0.7106, 'grad_norm': 1.924271821975708, 'learning_rate': 9.26070038910506e-05, 'epoch': 0.55}\n",
      "{'loss': 0.7012, 'grad_norm': 1.8720170259475708, 'learning_rate': 9.182879377431906e-05, 'epoch': 0.56}\n",
      "{'loss': 0.797, 'grad_norm': 2.212120294570923, 'learning_rate': 9.105058365758756e-05, 'epoch': 0.56}\n",
      "{'loss': 1.0673, 'grad_norm': 1.7496641874313354, 'learning_rate': 9.027237354085604e-05, 'epoch': 0.57}\n",
      "{'loss': 1.3554, 'grad_norm': 1.8354120254516602, 'learning_rate': 8.949416342412453e-05, 'epoch': 0.57}\n",
      "{'loss': 0.8254, 'grad_norm': 1.5327225923538208, 'learning_rate': 8.8715953307393e-05, 'epoch': 0.57}\n",
      "{'loss': 1.1185, 'grad_norm': 1.4983054399490356, 'learning_rate': 8.793774319066149e-05, 'epoch': 0.58}\n",
      "{'loss': 0.6959, 'grad_norm': 1.5967602729797363, 'learning_rate': 8.715953307392997e-05, 'epoch': 0.58}\n",
      "{'loss': 1.5279, 'grad_norm': 1.5562571287155151, 'learning_rate': 8.638132295719846e-05, 'epoch': 0.58}\n",
      "{'loss': 1.3915, 'grad_norm': 1.690966010093689, 'learning_rate': 8.560311284046692e-05, 'epoch': 0.59}\n",
      "{'loss': 0.9987, 'grad_norm': 1.2716020345687866, 'learning_rate': 8.482490272373542e-05, 'epoch': 0.59}\n",
      "{'loss': 0.9873, 'grad_norm': 1.1377315521240234, 'learning_rate': 8.40466926070039e-05, 'epoch': 0.6}\n",
      "{'loss': 1.0268, 'grad_norm': 1.1129367351531982, 'learning_rate': 8.326848249027238e-05, 'epoch': 0.6}\n",
      "{'loss': 1.0677, 'grad_norm': 1.209273338317871, 'learning_rate': 8.249027237354085e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2676, 'grad_norm': 1.2928547859191895, 'learning_rate': 8.171206225680935e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b274672c24e542cfbcccd471ffb3c06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8092658519744873, 'eval_runtime': 7.1682, 'eval_samples_per_second': 8.37, 'eval_steps_per_second': 8.37, 'epoch': 0.61}\n",
      "{'loss': 0.845, 'grad_norm': 1.2524007558822632, 'learning_rate': 8.093385214007783e-05, 'epoch': 0.61}\n",
      "{'loss': 0.9633, 'grad_norm': 1.1888108253479004, 'learning_rate': 8.01556420233463e-05, 'epoch': 0.61}\n",
      "{'loss': 0.8437, 'grad_norm': 1.3482218980789185, 'learning_rate': 7.937743190661478e-05, 'epoch': 0.62}\n",
      "{'loss': 0.9326, 'grad_norm': 1.2056831121444702, 'learning_rate': 7.859922178988328e-05, 'epoch': 0.62}\n",
      "{'loss': 1.1795, 'grad_norm': 1.1872425079345703, 'learning_rate': 7.782101167315176e-05, 'epoch': 0.63}\n",
      "{'loss': 1.3429, 'grad_norm': 1.2588169574737549, 'learning_rate': 7.704280155642024e-05, 'epoch': 0.63}\n",
      "{'loss': 1.0006, 'grad_norm': 1.1733083724975586, 'learning_rate': 7.626459143968871e-05, 'epoch': 0.63}\n",
      "{'loss': 1.4383, 'grad_norm': 1.5050380229949951, 'learning_rate': 7.54863813229572e-05, 'epoch': 0.64}\n",
      "{'loss': 1.1078, 'grad_norm': 1.3687278032302856, 'learning_rate': 7.470817120622569e-05, 'epoch': 0.64}\n",
      "{'loss': 0.8936, 'grad_norm': 1.120310664176941, 'learning_rate': 7.392996108949417e-05, 'epoch': 0.64}\n",
      "{'loss': 0.8683, 'grad_norm': 1.0460810661315918, 'learning_rate': 7.315175097276265e-05, 'epoch': 0.65}\n",
      "{'loss': 0.7671, 'grad_norm': 0.9633055329322815, 'learning_rate': 7.237354085603112e-05, 'epoch': 0.65}\n",
      "{'loss': 0.7065, 'grad_norm': 0.9729068875312805, 'learning_rate': 7.159533073929962e-05, 'epoch': 0.66}\n",
      "{'loss': 0.9632, 'grad_norm': 1.228331446647644, 'learning_rate': 7.08171206225681e-05, 'epoch': 0.66}\n",
      "{'loss': 0.6072, 'grad_norm': 0.8847576379776001, 'learning_rate': 7.003891050583658e-05, 'epoch': 0.66}\n",
      "{'loss': 0.6986, 'grad_norm': 1.1443923711776733, 'learning_rate': 6.926070038910505e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6826, 'grad_norm': 1.1795179843902588, 'learning_rate': 6.848249027237355e-05, 'epoch': 0.67}\n",
      "{'loss': 0.8609, 'grad_norm': 1.204282522201538, 'learning_rate': 6.770428015564203e-05, 'epoch': 0.67}\n",
      "{'loss': 0.8336, 'grad_norm': 1.252130389213562, 'learning_rate': 6.69260700389105e-05, 'epoch': 0.68}\n",
      "{'loss': 0.8813, 'grad_norm': 1.3050823211669922, 'learning_rate': 6.614785992217898e-05, 'epoch': 0.68}\n",
      "{'loss': 0.6252, 'grad_norm': 1.2293689250946045, 'learning_rate': 6.536964980544748e-05, 'epoch': 0.69}\n",
      "{'loss': 0.6911, 'grad_norm': 1.1821478605270386, 'learning_rate': 6.459143968871596e-05, 'epoch': 0.69}\n",
      "{'loss': 0.7576, 'grad_norm': 1.2706254720687866, 'learning_rate': 6.381322957198444e-05, 'epoch': 0.69}\n",
      "{'loss': 0.6443, 'grad_norm': 1.3395823240280151, 'learning_rate': 6.303501945525292e-05, 'epoch': 0.7}\n",
      "{'loss': 0.6819, 'grad_norm': 1.3155041933059692, 'learning_rate': 6.225680933852141e-05, 'epoch': 0.7}\n",
      "{'loss': 0.5936, 'grad_norm': 1.2766040563583374, 'learning_rate': 6.147859922178989e-05, 'epoch': 0.7}\n",
      "{'loss': 0.8405, 'grad_norm': 1.5334824323654175, 'learning_rate': 6.0700389105058366e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3881, 'grad_norm': 1.1489301919937134, 'learning_rate': 5.992217898832685e-05, 'epoch': 0.71}\n",
      "{'loss': 0.5101, 'grad_norm': 1.221561074256897, 'learning_rate': 5.914396887159533e-05, 'epoch': 0.72}\n",
      "{'loss': 0.8961, 'grad_norm': 1.6535812616348267, 'learning_rate': 5.836575875486382e-05, 'epoch': 0.72}\n",
      "{'loss': 1.2173, 'grad_norm': 1.9723172187805176, 'learning_rate': 5.7587548638132296e-05, 'epoch': 0.72}\n",
      "{'loss': 0.7793, 'grad_norm': 1.8959251642227173, 'learning_rate': 5.6809338521400776e-05, 'epoch': 0.73}\n",
      "{'loss': 0.7068, 'grad_norm': 1.7023919820785522, 'learning_rate': 5.603112840466926e-05, 'epoch': 0.73}\n",
      "{'loss': 0.936, 'grad_norm': 1.9433645009994507, 'learning_rate': 5.525291828793775e-05, 'epoch': 0.73}\n",
      "{'loss': 0.735, 'grad_norm': 1.7568058967590332, 'learning_rate': 5.447470817120623e-05, 'epoch': 0.74}\n",
      "{'loss': 0.6931, 'grad_norm': 1.7734034061431885, 'learning_rate': 5.3696498054474706e-05, 'epoch': 0.74}\n",
      "{'loss': 0.6929, 'grad_norm': 1.844046711921692, 'learning_rate': 5.291828793774319e-05, 'epoch': 0.75}\n",
      "{'loss': 0.6815, 'grad_norm': 2.12213397026062, 'learning_rate': 5.214007782101168e-05, 'epoch': 0.75}\n",
      "{'loss': 0.9193, 'grad_norm': 1.483970046043396, 'learning_rate': 5.136186770428015e-05, 'epoch': 0.75}\n",
      "{'loss': 0.6043, 'grad_norm': 1.010440707206726, 'learning_rate': 5.0583657587548636e-05, 'epoch': 0.76}\n",
      "{'loss': 0.8053, 'grad_norm': 1.2627346515655518, 'learning_rate': 4.980544747081712e-05, 'epoch': 0.76}\n",
      "{'loss': 0.7082, 'grad_norm': 1.2226883172988892, 'learning_rate': 4.90272373540856e-05, 'epoch': 0.76}\n",
      "{'loss': 1.3519, 'grad_norm': 1.4726932048797607, 'learning_rate': 4.824902723735409e-05, 'epoch': 0.77}\n",
      "{'loss': 1.0316, 'grad_norm': 1.2666888236999512, 'learning_rate': 4.7470817120622567e-05, 'epoch': 0.77}\n",
      "{'loss': 1.1912, 'grad_norm': 1.3412407636642456, 'learning_rate': 4.669260700389105e-05, 'epoch': 0.78}\n",
      "{'loss': 0.9804, 'grad_norm': 1.2866307497024536, 'learning_rate': 4.591439688715953e-05, 'epoch': 0.78}\n",
      "{'loss': 1.1238, 'grad_norm': 1.3310099840164185, 'learning_rate': 4.513618677042802e-05, 'epoch': 0.78}\n",
      "{'loss': 0.9779, 'grad_norm': 1.158477783203125, 'learning_rate': 4.43579766536965e-05, 'epoch': 0.79}\n",
      "{'loss': 0.615, 'grad_norm': 0.9956477880477905, 'learning_rate': 4.357976653696498e-05, 'epoch': 0.79}\n",
      "{'loss': 0.8688, 'grad_norm': 1.1236040592193604, 'learning_rate': 4.280155642023346e-05, 'epoch': 0.79}\n",
      "{'loss': 1.0329, 'grad_norm': 1.2056941986083984, 'learning_rate': 4.202334630350195e-05, 'epoch': 0.8}\n",
      "{'loss': 1.131, 'grad_norm': 1.352006196975708, 'learning_rate': 4.124513618677043e-05, 'epoch': 0.8}\n",
      "{'loss': 0.6881, 'grad_norm': 1.1217482089996338, 'learning_rate': 4.046692607003891e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1202, 'grad_norm': 1.1193838119506836, 'learning_rate': 3.968871595330739e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae558df053c643f69f9f0874c47b1cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7645450830459595, 'eval_runtime': 7.1665, 'eval_samples_per_second': 8.372, 'eval_steps_per_second': 8.372, 'epoch': 0.81}\n",
      "{'loss': 0.6383, 'grad_norm': 1.0341718196868896, 'learning_rate': 3.891050583657588e-05, 'epoch': 0.81}\n",
      "{'loss': 1.2019, 'grad_norm': 1.2994176149368286, 'learning_rate': 3.813229571984436e-05, 'epoch': 0.82}\n",
      "{'loss': 1.1588, 'grad_norm': 1.256150484085083, 'learning_rate': 3.735408560311284e-05, 'epoch': 0.82}\n",
      "{'loss': 1.1317, 'grad_norm': 1.267090916633606, 'learning_rate': 3.657587548638132e-05, 'epoch': 0.82}\n",
      "{'loss': 0.8991, 'grad_norm': 1.248318076133728, 'learning_rate': 3.579766536964981e-05, 'epoch': 0.83}\n",
      "{'loss': 0.8528, 'grad_norm': 1.147974967956543, 'learning_rate': 3.501945525291829e-05, 'epoch': 0.83}\n",
      "{'loss': 0.529, 'grad_norm': 1.159918189048767, 'learning_rate': 3.4241245136186774e-05, 'epoch': 0.84}\n",
      "{'loss': 1.0075, 'grad_norm': 1.416674017906189, 'learning_rate': 3.346303501945525e-05, 'epoch': 0.84}\n",
      "{'loss': 0.5635, 'grad_norm': 1.1614277362823486, 'learning_rate': 3.268482490272374e-05, 'epoch': 0.84}\n",
      "{'loss': 1.2465, 'grad_norm': 1.4761474132537842, 'learning_rate': 3.190661478599222e-05, 'epoch': 0.85}\n",
      "{'loss': 0.6328, 'grad_norm': 0.9788388609886169, 'learning_rate': 3.1128404669260704e-05, 'epoch': 0.85}\n",
      "{'loss': 1.0702, 'grad_norm': 1.4534378051757812, 'learning_rate': 3.0350194552529183e-05, 'epoch': 0.85}\n",
      "{'loss': 1.1879, 'grad_norm': 1.2843683958053589, 'learning_rate': 2.9571984435797666e-05, 'epoch': 0.86}\n",
      "{'loss': 0.7224, 'grad_norm': 1.444889783859253, 'learning_rate': 2.8793774319066148e-05, 'epoch': 0.86}\n",
      "{'loss': 0.7059, 'grad_norm': 1.2563023567199707, 'learning_rate': 2.801556420233463e-05, 'epoch': 0.87}\n",
      "{'loss': 0.7431, 'grad_norm': 1.2208616733551025, 'learning_rate': 2.7237354085603113e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4994, 'grad_norm': 1.28840172290802, 'learning_rate': 2.6459143968871596e-05, 'epoch': 0.87}\n",
      "{'loss': 0.4531, 'grad_norm': 1.073952078819275, 'learning_rate': 2.5680933852140075e-05, 'epoch': 0.88}\n",
      "{'loss': 0.9351, 'grad_norm': 1.4327733516693115, 'learning_rate': 2.490272373540856e-05, 'epoch': 0.88}\n",
      "{'loss': 0.6073, 'grad_norm': 1.4558194875717163, 'learning_rate': 2.4124513618677044e-05, 'epoch': 0.88}\n",
      "{'loss': 0.6406, 'grad_norm': 1.3897809982299805, 'learning_rate': 2.3346303501945526e-05, 'epoch': 0.89}\n",
      "{'loss': 0.5373, 'grad_norm': 1.104887843132019, 'learning_rate': 2.256809338521401e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3924, 'grad_norm': 1.2366381883621216, 'learning_rate': 2.178988326848249e-05, 'epoch': 0.9}\n",
      "{'loss': 1.0091, 'grad_norm': 1.6567347049713135, 'learning_rate': 2.1011673151750974e-05, 'epoch': 0.9}\n",
      "{'loss': 0.6211, 'grad_norm': 1.2360893487930298, 'learning_rate': 2.0233463035019457e-05, 'epoch': 0.9}\n",
      "{'loss': 0.4792, 'grad_norm': 1.172376036643982, 'learning_rate': 1.945525291828794e-05, 'epoch': 0.91}\n",
      "{'loss': 0.5088, 'grad_norm': 1.3038409948349, 'learning_rate': 1.867704280155642e-05, 'epoch': 0.91}\n",
      "{'loss': 0.3147, 'grad_norm': 1.336647629737854, 'learning_rate': 1.7898832684824904e-05, 'epoch': 0.91}\n",
      "{'loss': 1.1664, 'grad_norm': 1.9962711334228516, 'learning_rate': 1.7120622568093387e-05, 'epoch': 0.92}\n",
      "{'loss': 0.957, 'grad_norm': 1.7440589666366577, 'learning_rate': 1.634241245136187e-05, 'epoch': 0.92}\n",
      "{'loss': 0.9003, 'grad_norm': 1.6812856197357178, 'learning_rate': 1.5564202334630352e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7925, 'grad_norm': 2.0592966079711914, 'learning_rate': 1.4785992217898833e-05, 'epoch': 0.93}\n",
      "{'loss': 0.8306, 'grad_norm': 2.089646100997925, 'learning_rate': 1.4007782101167315e-05, 'epoch': 0.93}\n",
      "{'loss': 0.6831, 'grad_norm': 1.9156723022460938, 'learning_rate': 1.3229571984435798e-05, 'epoch': 0.94}\n",
      "{'loss': 0.9091, 'grad_norm': 1.0737122297286987, 'learning_rate': 1.245136186770428e-05, 'epoch': 0.94}\n",
      "{'loss': 0.7349, 'grad_norm': 1.1979155540466309, 'learning_rate': 1.1673151750972763e-05, 'epoch': 0.94}\n",
      "{'loss': 0.7414, 'grad_norm': 1.0861976146697998, 'learning_rate': 1.0894941634241246e-05, 'epoch': 0.95}\n",
      "{'loss': 1.1088, 'grad_norm': 1.199523687362671, 'learning_rate': 1.0116731517509728e-05, 'epoch': 0.95}\n",
      "{'loss': 0.9192, 'grad_norm': 1.4310702085494995, 'learning_rate': 9.33852140077821e-06, 'epoch': 0.96}\n",
      "{'loss': 1.1761, 'grad_norm': 1.3557329177856445, 'learning_rate': 8.560311284046693e-06, 'epoch': 0.96}\n",
      "{'loss': 1.0447, 'grad_norm': 1.373281717300415, 'learning_rate': 7.782101167315176e-06, 'epoch': 0.96}\n",
      "{'loss': 0.7664, 'grad_norm': 1.1761194467544556, 'learning_rate': 7.003891050583658e-06, 'epoch': 0.97}\n",
      "{'loss': 0.729, 'grad_norm': 1.126478910446167, 'learning_rate': 6.22568093385214e-06, 'epoch': 0.97}\n",
      "{'loss': 0.5963, 'grad_norm': 1.0155627727508545, 'learning_rate': 5.447470817120623e-06, 'epoch': 0.97}\n",
      "{'loss': 0.6742, 'grad_norm': 1.0949666500091553, 'learning_rate': 4.669260700389105e-06, 'epoch': 0.98}\n",
      "{'loss': 0.8922, 'grad_norm': 1.616310477256775, 'learning_rate': 3.891050583657588e-06, 'epoch': 0.98}\n",
      "{'loss': 0.5248, 'grad_norm': 1.3643521070480347, 'learning_rate': 3.11284046692607e-06, 'epoch': 0.99}\n",
      "{'loss': 0.7175, 'grad_norm': 1.4504625797271729, 'learning_rate': 2.3346303501945527e-06, 'epoch': 0.99}\n",
      "{'loss': 0.8895, 'grad_norm': 1.7790274620056152, 'learning_rate': 1.556420233463035e-06, 'epoch': 0.99}\n",
      "{'loss': 0.6381, 'grad_norm': 1.716579794883728, 'learning_rate': 7.782101167315175e-07, 'epoch': 1.0}\n",
      "{'loss': 0.5699, 'grad_norm': 1.6438847780227661, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 161.3499, 'train_samples_per_second': 3.31, 'train_steps_per_second': 1.655, 'train_loss': 1.0071701993433277, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=267, training_loss=1.0071701993433277, metrics={'train_runtime': 161.3499, 'train_samples_per_second': 3.31, 'train_steps_per_second': 1.655, 'total_flos': 1267678764466176.0, 'train_loss': 1.0071701993433277, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer of the question is: \n",
      "\n",
      "<!--\n",
      "  This Behavior Tree first attempts to navigate to a position. If that fails, it will\n",
      "  then try to navigate to a specific goal.\n",
      "-->\n",
      "\n",
      "<root main_tree_to_execute=\"MainTree\">\n",
      "  <BehaviorTree ID=\"MainTree\">\n",
      "    <Sequence name=\"root_sequence\">\n",
      "      <Fallback name=\"root_fallback\">\n",
      "        <GoalReached/>\n",
      "        <NavigateToPose goal=\"{goal}\" name=\"navigate_to_pose\"/>\n",
      "      </Fallback>\n",
      "      <NavigateToPose goal=\"{goal}\" name=\"navigate_to_pose\"/>\n",
      "    </Sequence>\n",
      "  </BehaviorTree>\n",
      "</root>\n",
      "\n",
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text=\"The behavior tree orchestrates the navigation of a robot by periodically replanning its global path at a frequency of 1 Hz. It utilizes a pipeline sequence, where it first computes a path to a specified goal using a \\\"GridBased\\\" planner and then follows this computed path using a designated controller. This approach ensures that the robot continuously updates its path to adapt to dynamic environments or changing conditions, enabling it to navigate effectively towards its goal while avoiding obstacles or other potential disruptions.\"\n",
    "text=\"The behavior tree orchestrates the navigation of a robot to find a broken leaks\"\n",
    "inputs = tokenizer([\n",
    "    data_prompt.format(base_instruction,text, \"\")\n",
    "], return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 2020)\n",
    "\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer_short = answer[0].split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
    "print(\"Answer of the question is:\", answer_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>You will be provided a summary of a task performed by a behavior tree, and your objective is to express this behavior tree in XML format.\\n\\n### Input:\\nThe behavior tree orchestrates the navigation of a robot by periodically replanning its global path at a frequency of 1 Hz. It utilizes a pipeline sequence, where it first computes a path to a specified goal using a \"GridBased\" planner and then follows this computed path using a designated controller. This approach ensures that the robot continuously updates its path to adapt to dynamic environments or changing conditions, enabling it to navigate effectively towards its goal while avoiding obstacles or other potential disruptions.\\n\\n### Output:\\n<!--\\n  This Behavior Tree replans the global path periodically at 1 Hz.\\n-->\\n\\n<root main_tree_to_execute=\"MainTree\">\\n  <BehaviorTree ID=\"MainTree\">\\n    <PipelineSequence name=\"NavigateWithReplanning\">\\n      <RateController hz=\"1.0\">\\n        <ComputePathToPose goal=\"{goal}\" path=\"{path}\" planner_id=\"GridBased\"/>\\n      </RateController>\\n      <FollowPath path=\"{path}\"  controller_id=\"FollowPath\"/>\\n    </PipelineSequence>\\n  </BehaviorTree>\\n</root>\\n<|eot_id|>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
