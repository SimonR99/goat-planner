{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import (\n",
    "    PrefixTuningConfig,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\"\n",
    "\n",
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer= AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_context</th>\n",
       "      <th>actions_dictionary</th>\n",
       "      <th>query</th>\n",
       "      <th>explanation</th>\n",
       "      <th>bt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a beach chair and umbrella on the beach (28.3m...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>Can you please bring me the bowl of soup and t...</td>\n",
       "      <td>Good, I will first locate the bowl of soup in ...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a table with chairs (21.3m)\\ntwo men standing ...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you identify the man in the black jacket ...</td>\n",
       "      <td>In this scenario, I will first attempt to loca...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a black cow grazing in a field (54.5m)\\na man ...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you locate the person standing in front o...</td>\n",
       "      <td>In this scenario, I will attempt to locate the...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a blur of a person walking on a street (13.5m)...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you display a message on the laptop to re...</td>\n",
       "      <td>I will start by attempting to display a messag...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a group of men playing frc (64.7m)\\na polar be...</td>\n",
       "      <td>NavigateTo: Moves the robot to a specified tar...</td>\n",
       "      <td>\"Can you take the bowl filled with fruit and i...</td>\n",
       "      <td>I will first check if there is a bowl filled w...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      object_context  \\\n",
       "0  a beach chair and umbrella on the beach (28.3m...   \n",
       "1  a table with chairs (21.3m)\\ntwo men standing ...   \n",
       "2  a black cow grazing in a field (54.5m)\\na man ...   \n",
       "3  a blur of a person walking on a street (13.5m)...   \n",
       "4  a group of men playing frc (64.7m)\\na polar be...   \n",
       "\n",
       "                                  actions_dictionary  \\\n",
       "0  NavigateTo: Moves the robot to a specified tar...   \n",
       "1  NavigateTo: Moves the robot to a specified tar...   \n",
       "2  NavigateTo: Moves the robot to a specified tar...   \n",
       "3  NavigateTo: Moves the robot to a specified tar...   \n",
       "4  NavigateTo: Moves the robot to a specified tar...   \n",
       "\n",
       "                                               query  \\\n",
       "0  Can you please bring me the bowl of soup and t...   \n",
       "1  \"Can you identify the man in the black jacket ...   \n",
       "2  \"Can you locate the person standing in front o...   \n",
       "3  \"Can you display a message on the laptop to re...   \n",
       "4  \"Can you take the bowl filled with fruit and i...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0  Good, I will first locate the bowl of soup in ...   \n",
       "1  In this scenario, I will first attempt to loca...   \n",
       "2  In this scenario, I will attempt to locate the...   \n",
       "3  I will start by attempting to display a messag...   \n",
       "4  I will first check if there is a bowl filled w...   \n",
       "\n",
       "                                                  bt  \n",
       "0  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "1  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "2  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "3  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "4  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"../data/queries_dataset.json\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree.\n",
      "\n",
      "Object Context : \n",
      "a beach chair and umbrella on the beach (28.3m)\n",
      "a woman walking down the street with an umbrella (96.9m)\n",
      "a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Actions Dictionary:\n",
      "NavigateTo: Moves the robot to a specified target (e.g., location or object). (Arguments: target)\n",
      "Pick: Picks up a specified object. (Arguments: object)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "RequestAssistance: Requests help for a specific task. (Arguments: task)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "RunDiagnostics: Runs system diagnostics to check for issues. (Arguments: )\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>Can you please bring me the bowl of soup and t...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you identify the man in the black jacket ...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you locate the person standing in front o...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you display a message on the laptop to re...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are a helpful robot assistant named Goat t...</td>\n",
       "      <td>\"Can you take the bowl filled with fruit and i...</td>\n",
       "      <td>&lt;root main_tree_to_execute=\"MainTree\"&gt;\\n  &lt;Beh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  You are a helpful robot assistant named Goat t...   \n",
       "1  You are a helpful robot assistant named Goat t...   \n",
       "2  You are a helpful robot assistant named Goat t...   \n",
       "3  You are a helpful robot assistant named Goat t...   \n",
       "4  You are a helpful robot assistant named Goat t...   \n",
       "\n",
       "                                               input  \\\n",
       "0  Can you please bring me the bowl of soup and t...   \n",
       "1  \"Can you identify the man in the black jacket ...   \n",
       "2  \"Can you locate the person standing in front o...   \n",
       "3  \"Can you display a message on the laptop to re...   \n",
       "4  \"Can you take the bowl filled with fruit and i...   \n",
       "\n",
       "                                              output  \n",
       "0  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "1  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "2  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "3  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  \n",
       "4  <root main_tree_to_execute=\"MainTree\">\\n  <Beh...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_context = data['object_context']\n",
    "actions_dictionary = data['actions_dictionary']\n",
    "query = data['query']\n",
    "explanation = data['explanation']\n",
    "bt = data['bt']\n",
    "\n",
    "\n",
    "# Create df with the following columns: instruction, input, output\n",
    "def formatting_input(examples):\n",
    "    instruction = \"\"\"You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree.\n",
    "\n",
    "Object Context : \n",
    "{object_context}\n",
    "\n",
    "Actions Dictionary:\n",
    "{actions_dictionary}\n",
    "\"\"\"\n",
    "\n",
    "    instruction = instruction.format(object_context=examples['object_context'], actions_dictionary=examples['actions_dictionary'])\n",
    "    return instruction\n",
    "\n",
    "for i in range(len(data)):\n",
    "    instruction = formatting_input(data.iloc[i])\n",
    "    print(instruction)\n",
    "    break\n",
    "\n",
    "formatted_data = pd.DataFrame({\n",
    "    'instruction': instruction,\n",
    "    'input': query,\n",
    "    'output': bt,\n",
    "})\n",
    "\n",
    "formatted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90954a8101c4557b8829218d14094b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree.\n",
      "\n",
      "Object Context : \n",
      "a beach chair and umbrella on the beach (28.3m)\n",
      "a woman walking down the street with an umbrella (96.9m)\n",
      "a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Actions Dictionary:\n",
      "NavigateTo: Moves the robot to a specified target (e.g., location or object). (Arguments: target)\n",
      "Pick: Picks up a specified object. (Arguments: object)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "RequestAssistance: Requests help for a specific task. (Arguments: task)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "RunDiagnostics: Runs system diagnostics to check for issues. (Arguments: )\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Can you please bring me the bowl of soup and then release it on the table?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "<root main_tree_to_execute=\"MainTree\">\n",
      "  <BehaviorTree ID=\"MainTree\">\n",
      "    <Fallback>\n",
      "      <Sequence>\n",
      "        <Action ID=\"LocateObject\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"NavigateTo\" target=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Pick\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Place\" object=\"bowl_of_soup\" location=\"table\"/>\n",
      "      </Sequence>\n",
      "      <Action ID=\"RequestAssistance\" task=\"find_bowl_of_soup\"/>\n",
      "    </Fallback>\n",
      "  </BehaviorTree>\n",
      "</root>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = \"<|eot_id|>\"\n",
    "\n",
    "def formatting_prompt(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction,input_, output in zip(instructions, inputs, outputs):\n",
    "        text = data_prompt.format(instruction,input_, output)\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "\n",
    "# Create the dataset and apply the mapping\n",
    "training_data = Dataset.from_pandas(formatted_data)\n",
    "training_data = training_data.map(formatting_prompt, batched=True)\n",
    "\n",
    "# Display a sample for verification\n",
    "print(training_data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.local/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '0.13.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/simon/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/simon/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff326dfddec146f58b29b403d6060b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6a17d1fa0f4926852c2f54c0737c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "\n",
    "\n",
    "# LoRA config\n",
    "peft_config = PrefixTuningConfig(\n",
    "    num_virtual_tokens=30,  # Number of virtual tokens\n",
    "    task_type=\"CAUSAL_LM\",  # Task type\n",
    ")\n",
    "\n",
    "\n",
    "new_model = \"llama-3.2-1b-bt-generator-prefix\"\n",
    "\n",
    "#Hyperparamter\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "# Create train/test split\n",
    "full_dataset = training_data.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=full_dataset[\"train\"],\n",
    "    eval_dataset=full_dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2374075403640fba30caadaba6de2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful robot assistant named Goat that can answer questions or execute actions by generating a behavior tree.\n",
      "\n",
      "Object Context : \n",
      "a beach chair and umbrella on the beach (28.3m)\n",
      "a woman walking down the street with an umbrella (96.9m)\n",
      "a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Actions Dictionary:\n",
      "NavigateTo: Moves the robot to a specified target (e.g., location or object). (Arguments: target)\n",
      "Pick: Picks up a specified object. (Arguments: object)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "RequestAssistance: Requests help for a specific task. (Arguments: task)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "RunDiagnostics: Runs system diagnostics to check for issues. (Arguments: )\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "<|eot_id|>\n",
      "<|start_header_id|>user<|end_header_id|>\n",
      "Can you please bring me the bowl of soup and then release it on the table?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "<root main_tree_to_execute=\"MainTree\">\n",
      "  <BehaviorTree ID=\"MainTree\">\n",
      "    <Fallback>\n",
      "      <Sequence>\n",
      "        <Action ID=\"LocateObject\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"NavigateTo\" target=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Pick\" object=\"bowl_of_soup\"/>\n",
      "        <Action ID=\"Place\" object=\"bowl_of_soup\" location=\"table\"/>\n",
      "      </Sequence>\n",
      "      <Action ID=\"RequestAssistance\" task=\"find_bowl_of_soup\"/>\n",
      "    </Fallback>\n",
      "  </BehaviorTree>\n",
      "</root>\n"
     ]
    }
   ],
   "source": [
    "data_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = \"<|eot_id|>\"\n",
    "\n",
    "def formatting_prompt(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction,input_, output in zip(instructions, inputs, outputs):\n",
    "        text = data_prompt.format(instruction,input_, output)\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "\n",
    "# Create the dataset and apply the mapping\n",
    "training_data = Dataset.from_pandas(formatted_data)\n",
    "training_data = training_data.map(formatting_prompt, batched=True)\n",
    "\n",
    "# Display a sample for verification\n",
    "print(training_data[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer of the question is: \n",
      "I will execute the action of bringing the bowl of soup and then release it on the table.\n",
      "\n",
      "Actions Executed:\n",
      "- Bring: Moves the robot to the bowl of soup (28.3m)\n",
      "- Release: Places the bowl of soup on the table (0.0m)\n",
      "\n",
      "Result:\n",
      "The bowl of soup is now on the table.\n",
      "\n",
      "Object Context remains the same: a beach chair and umbrella on the beach (28.3m), a woman walking down the street with an umbrella (96.9m), a blur of a person in a classroom (95.0m)\n",
      "\n",
      "Next Action:\n",
      "- LocateObject: Searches for the bowl of soup in the environment.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "instructions = training_data[\"instruction\"][0]\n",
    "inputs = training_data[\"input\"][0]\n",
    "outputs = training_data[\"output\"][0]\n",
    "text = data_prompt.format(instructions, inputs, \"\")\n",
    "\n",
    "inputs = tokenizer([\n",
    "    text\n",
    "], return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 2020, use_cache = True)\n",
    "\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer=answer[0].split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimonroy99\u001b[0m (\u001b[33msimonroy99-cole-de-technologie-sup-rieure\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/simon/workspace/ETS/SYS819/proteus/training/wandb/run-20241127_180539-5k35tq2b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/5k35tq2b' target=\"_blank\">llama-3.2-1b-bt-generator-prefix</a></strong> to <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface' target=\"_blank\">https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/5k35tq2b' target=\"_blank\">https://wandb.ai/simonroy99-cole-de-technologie-sup-rieure/huggingface/runs/5k35tq2b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9292294895db4502997a6ad222ccdd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.0998, 'grad_norm': 0.8972693681716919, 'learning_rate': 2e-05, 'epoch': 0.02}\n",
      "{'loss': 12.0266, 'grad_norm': 0.8810555934906006, 'learning_rate': 4e-05, 'epoch': 0.04}\n",
      "{'loss': 12.099, 'grad_norm': 0.9255397319793701, 'learning_rate': 6e-05, 'epoch': 0.07}\n",
      "{'loss': 11.9771, 'grad_norm': 0.9212969541549683, 'learning_rate': 8e-05, 'epoch': 0.09}\n",
      "{'loss': 11.9784, 'grad_norm': 0.9261974692344666, 'learning_rate': 0.0001, 'epoch': 0.11}\n",
      "{'loss': 11.8053, 'grad_norm': 0.969542384147644, 'learning_rate': 0.00012, 'epoch': 0.13}\n",
      "{'loss': 11.758, 'grad_norm': 0.9381641149520874, 'learning_rate': 0.00014, 'epoch': 0.16}\n",
      "{'loss': 11.7821, 'grad_norm': 0.961219310760498, 'learning_rate': 0.00016, 'epoch': 0.18}\n",
      "{'loss': 11.639, 'grad_norm': 1.0287214517593384, 'learning_rate': 0.00018, 'epoch': 0.2}\n",
      "{'loss': 11.4382, 'grad_norm': 1.0965269804000854, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "{'loss': 11.2884, 'grad_norm': 1.1242878437042236, 'learning_rate': 0.0001984, 'epoch': 0.24}\n",
      "{'loss': 11.8153, 'grad_norm': 0.8269811272621155, 'learning_rate': 0.0001968, 'epoch': 0.27}\n",
      "{'loss': 11.9045, 'grad_norm': 0.7809467315673828, 'learning_rate': 0.0001952, 'epoch': 0.29}\n",
      "{'loss': 11.775, 'grad_norm': 0.7591817378997803, 'learning_rate': 0.00019360000000000002, 'epoch': 0.31}\n",
      "{'loss': 11.7272, 'grad_norm': 0.7638949155807495, 'learning_rate': 0.000192, 'epoch': 0.33}\n",
      "{'loss': 11.5936, 'grad_norm': 0.7488244771957397, 'learning_rate': 0.0001904, 'epoch': 0.36}\n",
      "{'loss': 11.5958, 'grad_norm': 0.7354316711425781, 'learning_rate': 0.0001888, 'epoch': 0.38}\n",
      "{'loss': 11.5358, 'grad_norm': 0.7345198392868042, 'learning_rate': 0.00018720000000000002, 'epoch': 0.4}\n",
      "{'loss': 11.462, 'grad_norm': 0.7318169474601746, 'learning_rate': 0.0001856, 'epoch': 0.42}\n",
      "{'loss': 11.3185, 'grad_norm': 0.756904125213623, 'learning_rate': 0.00018400000000000003, 'epoch': 0.44}\n",
      "{'loss': 11.045, 'grad_norm': 0.8408666849136353, 'learning_rate': 0.00018240000000000002, 'epoch': 0.47}\n",
      "{'loss': 10.7261, 'grad_norm': 0.9101732969284058, 'learning_rate': 0.0001808, 'epoch': 0.49}\n",
      "{'loss': 11.7032, 'grad_norm': 0.6824796795845032, 'learning_rate': 0.00017920000000000002, 'epoch': 0.51}\n",
      "{'loss': 11.6115, 'grad_norm': 0.6525716781616211, 'learning_rate': 0.0001776, 'epoch': 0.53}\n",
      "{'loss': 11.4776, 'grad_norm': 0.655731201171875, 'learning_rate': 0.00017600000000000002, 'epoch': 0.56}\n",
      "{'loss': 11.4388, 'grad_norm': 0.6593590378761292, 'learning_rate': 0.0001744, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 11.4016, 'grad_norm': 0.6568716168403625, 'learning_rate': 0.0001728, 'epoch': 0.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dde22b5cf584624aed5dc35483c8145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.064292907714844, 'eval_runtime': 1.0593, 'eval_samples_per_second': 9.44, 'eval_steps_per_second': 9.44, 'epoch': 0.6}\n",
      "{'loss': 11.3786, 'grad_norm': 0.635890543460846, 'learning_rate': 0.00017120000000000001, 'epoch': 0.62}\n",
      "{'loss': 11.2793, 'grad_norm': 0.6475136280059814, 'learning_rate': 0.0001696, 'epoch': 0.64}\n",
      "{'loss': 11.0392, 'grad_norm': 0.6697637438774109, 'learning_rate': 0.000168, 'epoch': 0.67}\n",
      "{'loss': 10.6463, 'grad_norm': 0.7631388306617737, 'learning_rate': 0.0001664, 'epoch': 0.69}\n",
      "{'loss': 10.5948, 'grad_norm': 0.7601417303085327, 'learning_rate': 0.0001648, 'epoch': 0.71}\n",
      "{'loss': 10.4571, 'grad_norm': 0.7995731234550476, 'learning_rate': 0.0001632, 'epoch': 0.73}\n",
      "{'loss': 11.3247, 'grad_norm': 0.6531544327735901, 'learning_rate': 0.00016160000000000002, 'epoch': 0.76}\n",
      "{'loss': 11.398, 'grad_norm': 0.6191014647483826, 'learning_rate': 0.00016, 'epoch': 0.78}\n",
      "{'loss': 11.308, 'grad_norm': 0.6139654517173767, 'learning_rate': 0.00015840000000000003, 'epoch': 0.8}\n",
      "{'loss': 11.3272, 'grad_norm': 0.6077685356140137, 'learning_rate': 0.00015680000000000002, 'epoch': 0.82}\n",
      "{'loss': 11.2088, 'grad_norm': 0.6080785393714905, 'learning_rate': 0.0001552, 'epoch': 0.84}\n",
      "{'loss': 11.2628, 'grad_norm': 0.6116370558738708, 'learning_rate': 0.00015360000000000002, 'epoch': 0.87}\n",
      "{'loss': 11.1285, 'grad_norm': 0.6077624559402466, 'learning_rate': 0.000152, 'epoch': 0.89}\n",
      "{'loss': 11.1289, 'grad_norm': 0.602088451385498, 'learning_rate': 0.0001504, 'epoch': 0.91}\n",
      "{'loss': 11.012, 'grad_norm': 0.6033708453178406, 'learning_rate': 0.0001488, 'epoch': 0.93}\n",
      "{'loss': 10.8047, 'grad_norm': 0.6139242649078369, 'learning_rate': 0.0001472, 'epoch': 0.96}\n",
      "{'loss': 10.279, 'grad_norm': 0.7239659428596497, 'learning_rate': 0.00014560000000000002, 'epoch': 0.98}\n",
      "{'loss': 10.9976, 'grad_norm': 0.6040593981742859, 'learning_rate': 0.000144, 'epoch': 1.0}\n",
      "{'loss': 11.1026, 'grad_norm': 0.6092339158058167, 'learning_rate': 0.0001424, 'epoch': 1.02}\n",
      "{'loss': 11.0683, 'grad_norm': 0.5993483066558838, 'learning_rate': 0.0001408, 'epoch': 1.04}\n",
      "{'loss': 11.1126, 'grad_norm': 0.5927356481552124, 'learning_rate': 0.0001392, 'epoch': 1.07}\n",
      "{'loss': 11.0022, 'grad_norm': 0.5930384397506714, 'learning_rate': 0.00013759999999999998, 'epoch': 1.09}\n",
      "{'loss': 10.8554, 'grad_norm': 0.5788547992706299, 'learning_rate': 0.00013600000000000003, 'epoch': 1.11}\n",
      "{'loss': 10.8438, 'grad_norm': 0.5797454118728638, 'learning_rate': 0.00013440000000000001, 'epoch': 1.13}\n",
      "{'loss': 10.7063, 'grad_norm': 0.5938631296157837, 'learning_rate': 0.0001328, 'epoch': 1.16}\n",
      "{'loss': 10.6823, 'grad_norm': 0.5864022374153137, 'learning_rate': 0.00013120000000000002, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.4797, 'grad_norm': 0.6087929606437683, 'learning_rate': 0.0001296, 'epoch': 1.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c184f68ad0754f55bf4237d1a375e620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.505821228027344, 'eval_runtime': 1.0498, 'eval_samples_per_second': 9.526, 'eval_steps_per_second': 9.526, 'epoch': 1.2}\n",
      "{'loss': 10.3604, 'grad_norm': 0.6282442808151245, 'learning_rate': 0.00012800000000000002, 'epoch': 1.22}\n",
      "{'loss': 10.0728, 'grad_norm': 0.6826703548431396, 'learning_rate': 0.0001264, 'epoch': 1.24}\n",
      "{'loss': 11.0055, 'grad_norm': 0.5656613111495972, 'learning_rate': 0.0001248, 'epoch': 1.27}\n",
      "{'loss': 10.9045, 'grad_norm': 0.582356333732605, 'learning_rate': 0.0001232, 'epoch': 1.29}\n",
      "{'loss': 10.7734, 'grad_norm': 0.5679881572723389, 'learning_rate': 0.0001216, 'epoch': 1.31}\n",
      "{'loss': 10.8503, 'grad_norm': 0.5773313641548157, 'learning_rate': 0.00012, 'epoch': 1.33}\n",
      "{'loss': 10.8226, 'grad_norm': 0.5659737586975098, 'learning_rate': 0.0001184, 'epoch': 1.36}\n",
      "{'loss': 10.6178, 'grad_norm': 0.5682089328765869, 'learning_rate': 0.00011679999999999999, 'epoch': 1.38}\n",
      "{'loss': 10.656, 'grad_norm': 0.5735082626342773, 'learning_rate': 0.0001152, 'epoch': 1.4}\n",
      "{'loss': 10.5857, 'grad_norm': 0.5646535158157349, 'learning_rate': 0.0001136, 'epoch': 1.42}\n",
      "{'loss': 10.4344, 'grad_norm': 0.5717903971672058, 'learning_rate': 0.00011200000000000001, 'epoch': 1.44}\n",
      "{'loss': 10.3049, 'grad_norm': 0.591232419013977, 'learning_rate': 0.00011040000000000001, 'epoch': 1.47}\n",
      "{'loss': 9.9445, 'grad_norm': 0.6732887625694275, 'learning_rate': 0.00010880000000000002, 'epoch': 1.49}\n",
      "{'loss': 10.7518, 'grad_norm': 0.5858253836631775, 'learning_rate': 0.00010720000000000002, 'epoch': 1.51}\n",
      "{'loss': 10.6902, 'grad_norm': 0.562420666217804, 'learning_rate': 0.0001056, 'epoch': 1.53}\n",
      "{'loss': 10.6729, 'grad_norm': 0.5680798292160034, 'learning_rate': 0.00010400000000000001, 'epoch': 1.56}\n",
      "{'loss': 10.6, 'grad_norm': 0.5744771361351013, 'learning_rate': 0.00010240000000000001, 'epoch': 1.58}\n",
      "{'loss': 10.6129, 'grad_norm': 0.5586134791374207, 'learning_rate': 0.00010080000000000001, 'epoch': 1.6}\n",
      "{'loss': 10.6608, 'grad_norm': 0.5627037882804871, 'learning_rate': 9.92e-05, 'epoch': 1.62}\n",
      "{'loss': 10.5372, 'grad_norm': 0.5537415146827698, 'learning_rate': 9.76e-05, 'epoch': 1.64}\n",
      "{'loss': 10.4921, 'grad_norm': 0.5549275875091553, 'learning_rate': 9.6e-05, 'epoch': 1.67}\n",
      "{'loss': 10.2566, 'grad_norm': 0.5753466486930847, 'learning_rate': 9.44e-05, 'epoch': 1.69}\n",
      "{'loss': 9.8436, 'grad_norm': 0.6553044319152832, 'learning_rate': 9.28e-05, 'epoch': 1.71}\n",
      "{'loss': 9.7558, 'grad_norm': 0.6914865970611572, 'learning_rate': 9.120000000000001e-05, 'epoch': 1.73}\n",
      "{'loss': 10.6205, 'grad_norm': 0.5893574357032776, 'learning_rate': 8.960000000000001e-05, 'epoch': 1.76}\n",
      "{'loss': 10.6114, 'grad_norm': 0.5650296211242676, 'learning_rate': 8.800000000000001e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.4675, 'grad_norm': 0.5401904582977295, 'learning_rate': 8.64e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd53f30f3f44985bfbc62f3b41ff97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.13664436340332, 'eval_runtime': 1.0598, 'eval_samples_per_second': 9.436, 'eval_steps_per_second': 9.436, 'epoch': 1.8}\n",
      "{'loss': 10.5063, 'grad_norm': 0.5574674606323242, 'learning_rate': 8.48e-05, 'epoch': 1.82}\n",
      "{'loss': 10.4385, 'grad_norm': 0.5474872589111328, 'learning_rate': 8.32e-05, 'epoch': 1.84}\n",
      "{'loss': 10.3328, 'grad_norm': 0.5469573736190796, 'learning_rate': 8.16e-05, 'epoch': 1.87}\n",
      "{'loss': 10.1753, 'grad_norm': 0.5543910264968872, 'learning_rate': 8e-05, 'epoch': 1.89}\n",
      "{'loss': 10.0788, 'grad_norm': 0.5717887282371521, 'learning_rate': 7.840000000000001e-05, 'epoch': 1.91}\n",
      "{'loss': 9.815, 'grad_norm': 0.6391775608062744, 'learning_rate': 7.680000000000001e-05, 'epoch': 1.93}\n",
      "{'loss': 9.687, 'grad_norm': 0.661594569683075, 'learning_rate': 7.52e-05, 'epoch': 1.96}\n",
      "{'loss': 9.3552, 'grad_norm': 0.7173839807510376, 'learning_rate': 7.36e-05, 'epoch': 1.98}\n",
      "{'loss': 10.5777, 'grad_norm': 0.5640469193458557, 'learning_rate': 7.2e-05, 'epoch': 2.0}\n",
      "{'loss': 10.5219, 'grad_norm': 0.5512298941612244, 'learning_rate': 7.04e-05, 'epoch': 2.02}\n",
      "{'loss': 10.4667, 'grad_norm': 0.5476794242858887, 'learning_rate': 6.879999999999999e-05, 'epoch': 2.04}\n",
      "{'loss': 10.4273, 'grad_norm': 0.5544003248214722, 'learning_rate': 6.720000000000001e-05, 'epoch': 2.07}\n",
      "{'loss': 10.3562, 'grad_norm': 0.5411192774772644, 'learning_rate': 6.560000000000001e-05, 'epoch': 2.09}\n",
      "{'loss': 10.3146, 'grad_norm': 0.540738046169281, 'learning_rate': 6.400000000000001e-05, 'epoch': 2.11}\n",
      "{'loss': 10.3466, 'grad_norm': 0.5537878274917603, 'learning_rate': 6.24e-05, 'epoch': 2.13}\n",
      "{'loss': 10.2767, 'grad_norm': 0.5492827296257019, 'learning_rate': 6.08e-05, 'epoch': 2.16}\n",
      "{'loss': 10.2321, 'grad_norm': 0.5467925667762756, 'learning_rate': 5.92e-05, 'epoch': 2.18}\n",
      "{'loss': 10.0318, 'grad_norm': 0.5553907752037048, 'learning_rate': 5.76e-05, 'epoch': 2.2}\n",
      "{'loss': 9.7018, 'grad_norm': 0.6098784804344177, 'learning_rate': 5.6000000000000006e-05, 'epoch': 2.22}\n",
      "{'loss': 9.5934, 'grad_norm': 0.6346186995506287, 'learning_rate': 5.440000000000001e-05, 'epoch': 2.24}\n",
      "{'loss': 10.5277, 'grad_norm': 0.5480098128318787, 'learning_rate': 5.28e-05, 'epoch': 2.27}\n",
      "{'loss': 10.3437, 'grad_norm': 0.5451359748840332, 'learning_rate': 5.1200000000000004e-05, 'epoch': 2.29}\n",
      "{'loss': 10.3954, 'grad_norm': 0.5473423600196838, 'learning_rate': 4.96e-05, 'epoch': 2.31}\n",
      "{'loss': 10.3886, 'grad_norm': 0.5280747413635254, 'learning_rate': 4.8e-05, 'epoch': 2.33}\n",
      "{'loss': 10.2918, 'grad_norm': 0.5401734113693237, 'learning_rate': 4.64e-05, 'epoch': 2.36}\n",
      "{'loss': 10.1633, 'grad_norm': 0.5432786345481873, 'learning_rate': 4.4800000000000005e-05, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.0274, 'grad_norm': 0.5395910739898682, 'learning_rate': 4.32e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb3bf3c4d024912a2f3ff2357d85047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.914584159851074, 'eval_runtime': 1.0592, 'eval_samples_per_second': 9.441, 'eval_steps_per_second': 9.441, 'epoch': 2.4}\n",
      "{'loss': 10.042, 'grad_norm': 0.5535166263580322, 'learning_rate': 4.16e-05, 'epoch': 2.42}\n",
      "{'loss': 9.8886, 'grad_norm': 0.550167441368103, 'learning_rate': 4e-05, 'epoch': 2.44}\n",
      "{'loss': 9.5514, 'grad_norm': 0.6326387524604797, 'learning_rate': 3.8400000000000005e-05, 'epoch': 2.47}\n",
      "{'loss': 9.1814, 'grad_norm': 0.6961883306503296, 'learning_rate': 3.68e-05, 'epoch': 2.49}\n",
      "{'loss': 10.3596, 'grad_norm': 0.5757396221160889, 'learning_rate': 3.52e-05, 'epoch': 2.51}\n",
      "{'loss': 10.3361, 'grad_norm': 0.5550801157951355, 'learning_rate': 3.3600000000000004e-05, 'epoch': 2.53}\n",
      "{'loss': 10.2752, 'grad_norm': 0.5450955033302307, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.56}\n",
      "{'loss': 10.2662, 'grad_norm': 0.5442425608634949, 'learning_rate': 3.04e-05, 'epoch': 2.58}\n",
      "{'loss': 10.2777, 'grad_norm': 0.5480378270149231, 'learning_rate': 2.88e-05, 'epoch': 2.6}\n",
      "{'loss': 10.267, 'grad_norm': 0.5255061388015747, 'learning_rate': 2.7200000000000004e-05, 'epoch': 2.62}\n",
      "{'loss': 10.0386, 'grad_norm': 0.5260083675384521, 'learning_rate': 2.5600000000000002e-05, 'epoch': 2.64}\n",
      "{'loss': 9.8263, 'grad_norm': 0.5555504560470581, 'learning_rate': 2.4e-05, 'epoch': 2.67}\n",
      "{'loss': 9.5801, 'grad_norm': 0.6201294660568237, 'learning_rate': 2.2400000000000002e-05, 'epoch': 2.69}\n",
      "{'loss': 9.4786, 'grad_norm': 0.6259971261024475, 'learning_rate': 2.08e-05, 'epoch': 2.71}\n",
      "{'loss': 9.4995, 'grad_norm': 0.6290700435638428, 'learning_rate': 1.9200000000000003e-05, 'epoch': 2.73}\n",
      "{'loss': 10.4401, 'grad_norm': 0.5535951852798462, 'learning_rate': 1.76e-05, 'epoch': 2.76}\n",
      "{'loss': 10.3678, 'grad_norm': 0.5377274751663208, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.78}\n",
      "{'loss': 10.4111, 'grad_norm': 0.5439339280128479, 'learning_rate': 1.44e-05, 'epoch': 2.8}\n",
      "{'loss': 10.1602, 'grad_norm': 0.5434052348136902, 'learning_rate': 1.2800000000000001e-05, 'epoch': 2.82}\n",
      "{'loss': 10.19, 'grad_norm': 0.5322632789611816, 'learning_rate': 1.1200000000000001e-05, 'epoch': 2.84}\n",
      "{'loss': 10.1548, 'grad_norm': 0.5330086946487427, 'learning_rate': 9.600000000000001e-06, 'epoch': 2.87}\n",
      "{'loss': 10.024, 'grad_norm': 0.5218808650970459, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.89}\n",
      "{'loss': 10.0233, 'grad_norm': 0.5238590240478516, 'learning_rate': 6.4000000000000006e-06, 'epoch': 2.91}\n",
      "{'loss': 10.0123, 'grad_norm': 0.5394970178604126, 'learning_rate': 4.800000000000001e-06, 'epoch': 2.93}\n",
      "{'loss': 9.8572, 'grad_norm': 0.5523332357406616, 'learning_rate': 3.2000000000000003e-06, 'epoch': 2.96}\n",
      "{'loss': 9.4753, 'grad_norm': 0.6181883215904236, 'learning_rate': 1.6000000000000001e-06, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.1121, 'grad_norm': 0.5206335783004761, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a574ecc17a024e58bb9a15c28d57c12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.839621543884277, 'eval_runtime': 1.0504, 'eval_samples_per_second': 9.521, 'eval_steps_per_second': 9.521, 'epoch': 3.0}\n",
      "{'train_runtime': 69.6178, 'train_samples_per_second': 3.878, 'train_steps_per_second': 1.939, 'train_loss': 10.665396005135996, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=135, training_loss=10.665396005135996, metrics={'train_runtime': 69.6178, 'train_samples_per_second': 3.878, 'train_steps_per_second': 1.939, 'total_flos': 663109545885696.0, 'train_loss': 10.665396005135996, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer of the question is: \n",
      "I'll bring the bowl of soup to you. I'll also place it on the table.\n",
      "\n",
      "Object Context: \n",
      "- A bowl of soup (10.0m) \n",
      "- A table (0.0m) \n",
      "\n",
      "Actions Dictionary:\n",
      "Bring: Moves the robot to a specified location. (Arguments: location)\n",
      "Place: Places an object at a specified location. (Arguments: object, location)\n",
      "Release: Releases an object from a specified location. (Arguments: object)\n",
      "LocateObject: Searches for a specified object in the environment. (Arguments: object)\n",
      "Wait: Waits for a specified amount of time. (Arguments: duration)\n",
      "Communicate: Sends a message to a user or another robot. (Arguments: message)\n",
      "MoveForward: Moves the robot forward by a specified distance. (Arguments: distance)\n",
      "ExecuteCommand: Runs a specified bash or system command. (Arguments: command)\n",
      "\n",
      "Your current position is at 28.3m. I am now 96.9m away from the woman walking down the street with an umbrella. I am currently at 95.0m away from the blur of a person in a classroom.\n",
      "\n",
      "What would you like me to do next?\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([\n",
    "    text\n",
    "], return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 2020, use_cache = True)\n",
    "\n",
    "answer=tokenizer.batch_decode(outputs)\n",
    "answer=answer[0].split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].split(EOS_TOKEN)[0]\n",
    "print(\"Answer of the question is:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
